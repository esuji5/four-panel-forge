#!/usr/bin/env python3
"""
YOLO11xã‚¢ãƒ‹ãƒ¡é¡”æ¤œå‡º + DINOv2ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è­˜åˆ¥çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
é«˜ç²¾åº¦ãªé¡”æ¤œå‡ºã¨è­˜åˆ¥ã‚’å®Ÿç¾ã™ã‚‹å®Œå…¨çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
"""

import torch
import torch.nn as nn
import cv2
import numpy as np
from pathlib import Path
from ultralytics import YOLO
from PIL import Image
import json
import logging
from datetime import datetime
from typing import List, Dict, Tuple, Optional, Union
from dataclasses import dataclass, asdict
from transformers import AutoImageProcessor, AutoModel
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib import font_manager

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆæ—¢å­˜ã®åˆ†é¡å™¨ã‚’å†åˆ©ç”¨ï¼‰
from yuyu_character_classifier import DINOv2CharacterClassifier

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class FaceDetection:
    """é¡”æ¤œå‡ºçµæœ"""
    bbox: Tuple[float, float, float, float]  # x1, y1, x2, y2
    confidence: float
    detection_id: int = 0
    
    @property
    def center(self) -> Tuple[float, float]:
        """ä¸­å¿ƒåº§æ¨™"""
        x1, y1, x2, y2 = self.bbox
        return ((x1 + x2) / 2, (y1 + y2) / 2)
    
    @property
    def area(self) -> float:
        """é¢ç©"""
        x1, y1, x2, y2 = self.bbox
        return (x2 - x1) * (y2 - y1)
    
    @property
    def width(self) -> float:
        """å¹…"""
        x1, _, x2, _ = self.bbox
        return x2 - x1
    
    @property
    def height(self) -> float:
        """é«˜ã•"""
        _, y1, _, y2 = self.bbox
        return y2 - y1


@dataclass
class CharacterIdentification:
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è­˜åˆ¥çµæœ"""
    character_name: str
    confidence: float
    all_probabilities: Dict[str, float]
    top_k_predictions: List[Dict[str, Union[str, float]]]


@dataclass
class FaceCharacterResult:
    """é¡”æ¤œå‡ºï¼‹ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è­˜åˆ¥ã®çµ±åˆçµæœ"""
    detection: FaceDetection
    identification: CharacterIdentification
    face_image: Optional[np.ndarray] = None
    
    def to_dict(self) -> Dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        result = {
            'bbox': list(self.detection.bbox),
            'detection_confidence': self.detection.confidence,
            'detection_id': self.detection.detection_id,
            'character': self.identification.character_name,
            'character_confidence': self.identification.confidence,
            'all_probabilities': self.identification.all_probabilities,
            'top_k_predictions': self.identification.top_k_predictions
        }
        return result


@dataclass
class ImageProcessingResult:
    """ç”»åƒå‡¦ç†çµæœ"""
    image_path: str
    image_size: Tuple[int, int]  # width, height
    results: List[FaceCharacterResult]
    processing_time: float
    timestamp: str
    
    def get_character_counts(self) -> Dict[str, int]:
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ"""
        counts = {}
        for result in self.results:
            char = result.identification.character_name
            counts[char] = counts.get(char, 0) + 1
        return counts
    
    def get_high_confidence_results(self, threshold: float = 0.8) -> List[FaceCharacterResult]:
        """é«˜ä¿¡é ¼åº¦çµæœã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        return [r for r in self.results if r.identification.confidence >= threshold]
    
    def to_dict(self) -> Dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return {
            'image_path': self.image_path,
            'image_size': list(self.image_size),
            'total_faces': len(self.results),
            'character_counts': self.get_character_counts(),
            'results': [r.to_dict() for r in self.results],
            'processing_time': self.processing_time,
            'timestamp': self.timestamp
        }


class YuyuYOLODINOv2Pipeline:
    """YOLO11x + DINOv2çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¥ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆ
    CHARACTER_COLORS = {
        'yuzuko': (255, 182, 193),   # ãƒ©ã‚¤ãƒˆãƒ”ãƒ³ã‚¯
        'yukari': (173, 216, 230),   # ãƒ©ã‚¤ãƒˆãƒ–ãƒ«ãƒ¼
        'yui': (144, 238, 144),      # ãƒ©ã‚¤ãƒˆã‚°ãƒªãƒ¼ãƒ³
        'yoriko': (255, 218, 185),   # ãƒ”ãƒ¼ãƒ
        'chiho': (221, 160, 221),    # ãƒ—ãƒ©ãƒ 
        'kei': (255, 222, 173),      # ãƒŠãƒãƒ›ãƒ›ãƒ¯ã‚¤ãƒˆ
        'fumi': (176, 196, 222),     # ãƒ©ã‚¤ãƒˆã‚¹ãƒãƒ¼ãƒ«ãƒ–ãƒ«ãƒ¼
        'unknown': (192, 192, 192)   # ã‚·ãƒ«ãƒãƒ¼
    }
    
    def __init__(
        self,
        yolo_model_path: str = "/Users/esuji/work/fun_annotator/yolo11x_face_detection_model/yolo11l_480_12_14.pt",
        dinov2_model_path: str = "/Users/esuji/work/fun_annotator/yuyu_face_recognize_model/yuyu_dinov2_final.pth",
        multiclass_model_path: str = "/Users/esuji/work/fun_annotator/yolo11x_face_detection_model/yolo11l_480_12_14_multi.pt",
        device: str = 'auto',
        detection_conf_threshold: float = 0.5,
        detection_iou_threshold: float = 0.45,
        classification_conf_threshold: float = 0.5,
        face_margin: float = 0.15,
        multiclass_mode: bool = False
    ):
        """
        åˆæœŸåŒ–
        
        Args:
            yolo_model_path: YOLO11xãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
            dinov2_model_path: DINOv2åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
            multiclass_model_path: ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹YOLOãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
            device: å®Ÿè¡Œãƒ‡ãƒã‚¤ã‚¹ ('auto', 'cpu', 'cuda')
            detection_conf_threshold: æ¤œå‡ºä¿¡é ¼åº¦é–¾å€¤
            detection_iou_threshold: NMS IoUé–¾å€¤
            classification_conf_threshold: åˆ†é¡ä¿¡é ¼åº¦é–¾å€¤
            face_margin: é¡”åˆ‡ã‚Šå‡ºã—æ™‚ã®ãƒãƒ¼ã‚¸ãƒ³æ¯”ç‡
            multiclass_mode: ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        """
        self.detection_conf_threshold = detection_conf_threshold
        self.detection_iou_threshold = detection_iou_threshold
        self.classification_conf_threshold = classification_conf_threshold
        self.face_margin = face_margin
        self.multiclass_mode = multiclass_mode
        self.multiclass_model_path = multiclass_model_path
        
        # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
        if device == 'auto':
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        logger.info(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self._load_models(yolo_model_path, dinov2_model_path)
        
        # ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ã‚¯ãƒ©ã‚¹åå®šç¾©
        self.multiclass_names = ['yuzuko', 'yukari', 'yui', 'yoriko', 'chiho', 'kei', 'fumi', 'other']
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'total_images': 0,
            'total_faces': 0,
            'total_identifications': 0,
            'character_counts': {},
            'processing_times': []
        }
        
        logger.info("ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–å®Œäº†")
    
    def _calculate_iou(self, bbox1, bbox2):
        """
        IoUï¼ˆIntersection over Unionï¼‰ã‚’è¨ˆç®—
        
        Args:
            bbox1, bbox2: (x1, y1, x2, y2) å½¢å¼ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
            
        Returns:
            IoUå€¤ (0.0-1.0)
        """
        x1_1, y1_1, x2_1, y2_1 = bbox1
        x1_2, y1_2, x2_2, y2_2 = bbox2
        
        # é‡è¤‡éƒ¨åˆ†ã®åº§æ¨™ã‚’è¨ˆç®—
        x1_inter = max(x1_1, x1_2)
        y1_inter = max(y1_1, y1_2)
        x2_inter = min(x2_1, x2_2)
        y2_inter = min(y2_1, y2_2)
        
        # é‡è¤‡ãŒãªã„å ´åˆ
        if x1_inter >= x2_inter or y1_inter >= y2_inter:
            return 0.0
        
        # é‡è¤‡é¢ç©
        inter_area = (x2_inter - x1_inter) * (y2_inter - y1_inter)
        
        # å„ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®é¢ç©
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        
        # Unioné¢ç©
        union_area = area1 + area2 - inter_area
        
        return inter_area / union_area if union_area > 0 else 0.0
    
    def _remove_duplicate_detections(self, results, iou_threshold=0.5):
        """
        é‡è¤‡ã™ã‚‹æ¤œå‡ºçµæœã‚’é™¤å»
        
        Args:
            results: FaceCharacterResultã®ãƒªã‚¹ãƒˆ
            iou_threshold: IoUé–¾å€¤ï¼ˆã“ã‚Œä»¥ä¸Šãªã‚‰é‡è¤‡ã¨ã¿ãªã™ï¼‰
            
        Returns:
            é‡è¤‡é™¤å»å¾Œã®resultsãƒªã‚¹ãƒˆ
        """
        if len(results) <= 1:
            return results
        
        # ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆï¼ˆé«˜ã„é †ï¼‰
        sorted_results = sorted(results, key=lambda r: r.identification.confidence, reverse=True)
        
        # é‡è¤‡é™¤å»
        keep_results = []
        for current in sorted_results:
            is_duplicate = False
            current_bbox = current.detection.bbox
            
            for kept in keep_results:
                kept_bbox = kept.detection.bbox
                iou = self._calculate_iou(current_bbox, kept_bbox)
                
                if iou > iou_threshold:
                    is_duplicate = True
                    logger.debug(f"é‡è¤‡é™¤å»: {current.identification.character_name}({current.identification.confidence:.3f}) <- IoU={iou:.3f}")
                    break
            
            if not is_duplicate:
                keep_results.append(current)
        
        logger.info(f"é‡è¤‡é™¤å»: {len(results)} -> {len(keep_results)}äºº")
        return keep_results
    
    def _filter_yukari_kei_duplicates(self, results):
        """
        æ—¥å‘ç¸ã¨å²¡é‡ä½³ã®é‡è¤‡æ¤œå‡ºã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        
        è¦‹ãŸç›®ãŒä¼¼ã¦ã„ã‚‹ãŸã‚åŒã˜äººç‰©ã‚’ç•°ãªã‚‹ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ã—ã¦æ¤œå‡ºã™ã‚‹å•é¡Œã‚’è§£æ±º
        åŒã˜ã‚³ãƒã«ä¸¡æ–¹ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã€ã‚ˆã‚Šé«˜ã„ä¿¡é ¼åº¦ã®æ–¹ã‚’æ¡ç”¨
        
        Args:
            results: FaceCharacterResultã®ãƒªã‚¹ãƒˆ
            
        Returns:
            ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®resultsãƒªã‚¹ãƒˆ
        """
        if len(results) <= 1:
            return results
        
        # ä¸¡æ–¹ã®åå‰å½¢å¼ï¼ˆæ—¥æœ¬èªãƒ»è‹±èªï¼‰ã«å¯¾å¿œ
        yukari_names = ['æ—¥å‘ç¸', 'yukari']
        kei_names = ['å²¡é‡ä½³', 'kei']
        
        # æ—¥å‘ç¸ã¨å²¡é‡ä½³ã®æ¤œå‡ºçµæœã‚’æŠ½å‡º
        yukari_detections = [r for r in results if r.identification.character_name in yukari_names]
        kei_detections = [r for r in results if r.identification.character_name in kei_names]
        other_detections = [r for r in results if r.identification.character_name not in yukari_names + kei_names]
        
        # ä¸¡æ–¹ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        if yukari_detections and kei_detections:
            logger.info(f"ğŸ” æ—¥å‘ç¸ãƒ»å²¡é‡ä½³é‡è¤‡æ¤œå‡ºãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–‹å§‹")
            yukari_names_str = [r.identification.character_name for r in yukari_detections]
            kei_names_str = [r.identification.character_name for r in kei_detections]
            logger.info(f"  ã‚†ã‹ã‚Šç³»: {len(yukari_detections)}ä»¶ ({yukari_names_str}, ä¿¡é ¼åº¦: {[f'{r.identification.confidence:.3f}' for r in yukari_detections]})")
            logger.info(f"  æµç³»: {len(kei_detections)}ä»¶ ({kei_names_str}, ä¿¡é ¼åº¦: {[f'{r.identification.confidence:.3f}' for r in kei_detections]})")
            
            # ä¸¡ã‚°ãƒ«ãƒ¼ãƒ—ã‹ã‚‰æœ€é«˜ä¿¡é ¼åº¦ã®ã‚‚ã®ã‚’é¸å‡º
            best_yukari = max(yukari_detections, key=lambda r: r.identification.confidence)
            best_kei = max(kei_detections, key=lambda r: r.identification.confidence)
            
            # ã¾ãšä½ç½®é–¢ä¿‚ã‚’ç¢ºèªï¼ˆé‡è¤‡æ¤œå‡ºã‹å®Ÿéš›ã«2äººã„ã‚‹ã‹ã‚’åˆ¤å®šï¼‰
            iou = self._calculate_iou(best_yukari.detection.bbox, best_kei.detection.bbox)
            logger.info(f"ä½ç½®é‡è¤‡åº¦ (IoU): {iou:.3f}")
            
            # ä¿¡é ¼åº¦å·®ã‚’è¨ˆç®—
            confidence_diff = abs(best_yukari.identification.confidence - best_kei.identification.confidence)
            
            # ä¿¡é ¼åº¦å·®ã®åˆ¤å®šé–¾å€¤
            CONFIDENCE_THRESHOLD = 0.15  # 15%ä»¥ä¸Šã®å·®ãŒã‚ã‚Œã°æ˜ç¢ºã«åŒºåˆ¥å¯èƒ½
            MIN_CONFIDENCE = 0.7  # æœ€ä½ä¿¡é ¼åº¦70%
            IoU_THRESHOLD = 0.3  # 30%ä»¥ä¸Šé‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã¯åŒä¸€äººç‰©ã®å¯èƒ½æ€§ãŒé«˜ã„
            
            if iou <= IoU_THRESHOLD:
                # ä½ç½®ãŒé›¢ã‚Œã¦ã„ã‚‹å ´åˆã¯å®Ÿéš›ã«2äººã„ã‚‹å¯èƒ½æ€§ãŒé«˜ã„
                logger.info(f"ğŸ‘¥ ä½ç½®ãŒé›¢ã‚Œã¦ã„ã‚‹ (IoU: {iou:.3f}) ãŸã‚ä¸¡æ–¹æ¡ç”¨ - å®Ÿéš›ã«2äººå­˜åœ¨")
                filtered_results = results
            elif confidence_diff >= CONFIDENCE_THRESHOLD:
                # ä¿¡é ¼åº¦ã«æ˜ç¢ºãªå·®ãŒã‚ã‚‹å ´åˆã€é«˜ã„æ–¹ã‚’æ¡ç”¨
                if best_yukari.identification.confidence > best_kei.identification.confidence:
                    chosen = best_yukari
                    rejected = best_kei
                else:
                    chosen = best_kei
                    rejected = best_yukari
                
                logger.info(f"âœ… ä¿¡é ¼åº¦å·® {confidence_diff:.3f} ã«ã‚ˆã‚Š {chosen.identification.character_name}({chosen.identification.confidence:.3f}) ã‚’æ¡ç”¨")
                logger.info(f"âŒ {rejected.identification.character_name}({rejected.identification.confidence:.3f}) ã‚’é™¤å¤–")
                
                # æ¡ç”¨ã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä»¥å¤–ã®åŒã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ¤œå‡ºã‚’é™¤å¤–
                if chosen.identification.character_name in yukari_names:
                    filtered_results = other_detections + yukari_detections
                else:
                    filtered_results = other_detections + kei_detections
            else:
                # ä½ç½®ãŒé‡è¤‡ã—ã¦ã„ã‚‹ãŒä¿¡é ¼åº¦å·®ãŒå°ã•ã„å ´åˆã€ã‚ˆã‚Šé«˜ã„ä¿¡é ¼åº¦ã®æ–¹ã‚’æ¡ç”¨
                logger.info(f"âš–ï¸ ä½ç½®é‡è¤‡ (IoU: {iou:.3f}) ã‹ã¤ä¿¡é ¼åº¦å·®ãŒå°ã•ã„ ({confidence_diff:.3f}) ãŸã‚é«˜ä¿¡é ¼åº¦ã‚’æ¡ç”¨")
                if best_yukari.identification.confidence >= best_kei.identification.confidence:
                    chosen = best_yukari
                    rejected = best_kei
                    filtered_results = other_detections + yukari_detections
                else:
                    chosen = best_kei
                    rejected = best_yukari
                    filtered_results = other_detections + kei_detections
                    
                logger.info(f"âœ… é«˜ä¿¡é ¼åº¦ã«ã‚ˆã‚Š {chosen.identification.character_name}({chosen.identification.confidence:.3f}) ã‚’æ¡ç”¨")
                logger.info(f"âŒ {rejected.identification.character_name}({rejected.identification.confidence:.3f}) ã‚’é™¤å¤–")
                    
            if len(filtered_results) != len(results):
                logger.info(f"ğŸ¯ æ—¥å‘ç¸ãƒ»å²¡é‡ä½³ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Œäº†: {len(results)} -> {len(filtered_results)}äºº")
            
            return filtered_results
        else:
            # é‡è¤‡ãŒãªã„å ´åˆã¯ãã®ã¾ã¾è¿”ã™
            return results
    
    def _filter_same_character_duplicates(self, results):
        """
        åŒã˜ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒè¤‡æ•°æ¤œå‡ºã•ã‚ŒãŸå ´åˆã®é‡è¤‡é™¤å»
        
        åŒã˜ã‚³ãƒã«åŒã˜ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒè¤‡æ•°æ¤œå‡ºã•ã‚ŒãŸå ´åˆã€æœ€ã‚‚ä¿¡é ¼åº¦ã®é«˜ã„ã‚‚ã®ã‚’æ¡ç”¨
        
        Args:
            results: FaceCharacterResultã®ãƒªã‚¹ãƒˆ
            
        Returns:
            ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®resultsãƒªã‚¹ãƒˆ
        """
        if len(results) <= 1:
            return results
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        character_groups = {}
        for result in results:
            char_name = result.identification.character_name
            if char_name not in character_groups:
                character_groups[char_name] = []
            character_groups[char_name].append(result)
        
        # å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã”ã¨ã«é‡è¤‡ãƒã‚§ãƒƒã‚¯
        filtered_results = []
        for char_name, char_results in character_groups.items():
            if len(char_results) == 1:
                # 1äººã ã‘ã®å ´åˆã¯ãã®ã¾ã¾è¿½åŠ 
                filtered_results.extend(char_results)
            else:
                # è¤‡æ•°æ¤œå‡ºã®å ´åˆã¯ä¿¡é ¼åº¦ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                logger.info(f"ğŸ”„ åŒä¸€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é‡è¤‡æ¤œå‡º: {char_name} ({len(char_results)}ä»¶)")
                
                # ä¿¡é ¼åº¦ã§ã‚½ãƒ¼ãƒˆï¼ˆé«˜ã„é †ï¼‰
                sorted_results = sorted(char_results, key=lambda r: r.identification.confidence, reverse=True)
                
                # æœ€é«˜ä¿¡é ¼åº¦ã®æ¤œå‡ºã‚’å–å¾—
                best_result = sorted_results[0]
                best_confidence = best_result.identification.confidence
                
                # ä¿¡é ¼åº¦å·®ã«ã‚ˆã‚‹åˆ¤å®š
                SAME_CHARACTER_CONFIDENCE_THRESHOLD = 0.10  # 10%ä»¥ä¸Šã®å·®ãŒã‚ã‚Œã°1ã¤ã«çµã‚‹ï¼ˆç·©å’Œï¼‰
                MIN_KEEP_CONFIDENCE = 0.8  # 80%ä»¥ä¸Šãªã‚‰è¤‡æ•°äººã®å¯èƒ½æ€§ã‚‚è€ƒæ…®
                
                keep_results = [best_result]  # æœ€é«˜ä¿¡é ¼åº¦ã¯å¿…ãšä¿æŒ
                
                for other_result in sorted_results[1:]:
                    other_confidence = other_result.identification.confidence
                    confidence_diff = best_confidence - other_confidence
                    
                    # IoUè¨ˆç®—ã§ä½ç½®é‡è¤‡ã‚’ãƒã‚§ãƒƒã‚¯
                    iou = self._calculate_iou(best_result.detection.bbox, other_result.detection.bbox)
                    
                    if confidence_diff >= SAME_CHARACTER_CONFIDENCE_THRESHOLD:
                        # æ—¥å‘ç¸ã®å ´åˆã€ä¿¡é ¼åº¦å·®ãŒå¤§ãã„ä½ã„æ–¹ã‚’å²¡é‡ä½³ã«å¤‰æ›´
                        if char_name in ['æ—¥å‘ç¸', 'yukari'] and other_confidence >= 0.6:
                            # å²¡é‡ä½³ã¨ã—ã¦å†åˆ†é¡
                            other_result.identification.character_name = 'å²¡é‡ä½³' if char_name == 'æ—¥å‘ç¸' else 'kei'
                            logger.info(f"  ğŸ”„ ä¿¡é ¼åº¦å·® {confidence_diff:.3f} ã«ã‚ˆã‚Šå²¡é‡ä½³ã«å†åˆ†é¡: {other_confidence:.3f}")
                            keep_results.append(other_result)
                        else:
                            # ãã®ä»–ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¯é™¤å¤–
                            logger.info(f"  âŒ ä¿¡é ¼åº¦å·® {confidence_diff:.3f} ã«ã‚ˆã‚Šé™¤å¤–: {other_confidence:.3f}")
                    elif iou > 0.4:  # 40%ä»¥ä¸Šé‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã¯åŒä¸€äººç‰©
                        logger.info(f"  âŒ ä½ç½®é‡è¤‡ (IoU: {iou:.3f}) ã«ã‚ˆã‚Šé™¤å¤–: {other_confidence:.3f}")
                    elif other_confidence >= MIN_KEEP_CONFIDENCE and confidence_diff < 0.1:
                        # ä¸¡æ–¹ã¨ã‚‚é«˜ä¿¡é ¼åº¦ã§å·®ãŒå°ã•ã„å ´åˆã¯ä¸¡æ–¹ä¿æŒï¼ˆå®Ÿéš›ã«2äººã„ã‚‹å¯èƒ½æ€§ï¼‰
                        keep_results.append(other_result)
                        logger.info(f"  âœ… é«˜ä¿¡é ¼åº¦ãƒ»ä½å·®åˆ†ã«ã‚ˆã‚Šä¿æŒ: {other_confidence:.3f} (å·®åˆ†: {confidence_diff:.3f})")
                    else:
                        logger.info(f"  âŒ é™¤å¤–: {other_confidence:.3f} (å·®åˆ†: {confidence_diff:.3f}, IoU: {iou:.3f})")
                
                filtered_results.extend(keep_results)
                
                if len(keep_results) != len(char_results):
                    logger.info(f"  ğŸ¯ {char_name} ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: {len(char_results)} -> {len(keep_results)}äºº")
        
        if len(filtered_results) != len(results):
            logger.info(f"ğŸ¯ åŒä¸€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é‡è¤‡é™¤å»å®Œäº†: {len(results)} -> {len(filtered_results)}äºº")
        
        return filtered_results
    
    def _load_models(self, yolo_path: str, dinov2_path: str):
        """ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰"""
        # YOLOãƒ¢ãƒ‡ãƒ«
        logger.info(f"YOLOãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰: {yolo_path}")
        try:
            self.yolo_model = YOLO(yolo_path)
            logger.info("YOLOãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        except Exception as e:
            logger.error(f"YOLOãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
            raise
        
        # ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹YOLOãƒ¢ãƒ‡ãƒ«
        logger.info(f"ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹YOLOãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰: {self.multiclass_model_path}")
        try:
            if Path(self.multiclass_model_path).exists():
                self.multiclass_yolo_model = YOLO(self.multiclass_model_path)
                logger.info("ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹YOLOãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")
            else:
                logger.warning(f"ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.multiclass_model_path}")
                self.multiclass_yolo_model = None
        except Exception as e:
            logger.error(f"ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹YOLOãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
            self.multiclass_yolo_model = None
        
        # DINOv2ãƒ¢ãƒ‡ãƒ«
        logger.info(f"DINOv2ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰: {dinov2_path}")
        try:
            self._load_dinov2_classifier(dinov2_path)
            logger.info("DINOv2ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        except Exception as e:
            logger.error(f"DINOv2ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
            raise
    
    def _load_dinov2_classifier(self, model_path: str):
        """DINOv2åˆ†é¡å™¨ã®ãƒ­ãƒ¼ãƒ‰"""
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ­ãƒ¼ãƒ‰
        checkpoint = torch.load(model_path, map_location=self.device)
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—
        model_config = checkpoint.get('model_config', {})
        num_classes = model_config.get('num_classes', 8)
        model_name = model_config.get('model_name', 'facebook/dinov2-base')
        
        # ã‚¯ãƒ©ã‚¹åè¨­å®š
        if 'class_to_idx' in checkpoint:
            self.class_to_idx = checkpoint['class_to_idx']
            self.class_names = [''] * len(self.class_to_idx)
            for class_name, idx in self.class_to_idx.items():
                self.class_names[idx] = class_name
        else:
            self.class_names = ['yuzuko', 'yukari', 'yui', 'yoriko', 'chiho', 'kei', 'fumi', 'unknown']
        
        logger.info(f"ã‚¯ãƒ©ã‚¹: {self.class_names}")
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self.dinov2_model = DINOv2CharacterClassifier(num_classes=num_classes, model_name=model_name)
        
        # é‡ã¿ãƒ­ãƒ¼ãƒ‰
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        elif 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        else:
            state_dict = checkpoint
        
        self.dinov2_model.load_state_dict(state_dict)
        self.dinov2_model.to(self.device)
        self.dinov2_model.eval()
        
        # ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–
        self.processor = AutoImageProcessor.from_pretrained(model_name)
        
        # ãƒ¢ãƒ‡ãƒ«ç²¾åº¦æƒ…å ±
        if 'training_info' in checkpoint:
            training_info = checkpoint['training_info']
            best_acc = training_info.get('best_val_acc', 'Unknown')
            if isinstance(best_acc, float):
                logger.info(f"ãƒ¢ãƒ‡ãƒ«ç²¾åº¦: {best_acc:.4f}")
    
    def set_mode(self, multiclass_mode: bool):
        """
        æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã®è¨­å®š
        
        Args:
            multiclass_mode: Trueãªã‚‰ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ãƒ¢ãƒ¼ãƒ‰ã€Falseãªã‚‰é¡”æ¤œå‡º+èªè­˜ãƒ¢ãƒ¼ãƒ‰
        """
        if multiclass_mode and self.multiclass_yolo_model is None:
            logger.warning("ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚é¡”æ¤œå‡º+èªè­˜ãƒ¢ãƒ¼ãƒ‰ã‚’ç¶™ç¶šã—ã¾ã™ã€‚")
            return
        
        self.multiclass_mode = multiclass_mode
        mode_str = "ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹æ¤œå‡º" if multiclass_mode else "é¡”æ¤œå‡º+èªè­˜"
        logger.info(f"æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‚’ {mode_str} ã«è¨­å®šã—ã¾ã—ãŸ")
    
    def detect_multiclass_characters(self, image: np.ndarray) -> List[FaceCharacterResult]:
        """
        ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹YOLOã«ã‚ˆã‚‹ç›´æ¥çš„ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ¤œå‡º
        
        Args:
            image: å…¥åŠ›ç”»åƒ (BGR)
            
        Returns:
            ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ¤œå‡ºçµæœã®ãƒªã‚¹ãƒˆ
        """
        if self.multiclass_yolo_model is None:
            logger.error("ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return []
        
        results = self.multiclass_yolo_model(
            image,
            conf=self.detection_conf_threshold,
            iou=self.detection_iou_threshold,
            verbose=False
        )
        
        detections = []
        for r in results:
            if r.boxes is not None:
                for i, box in enumerate(r.boxes):
                    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
                    xyxy = box.xyxy[0].cpu().numpy()
                    x1, y1, x2, y2 = float(xyxy[0]), float(xyxy[1]), float(xyxy[2]), float(xyxy[3])
                    
                    # ä¿¡é ¼åº¦ã¨ã‚¯ãƒ©ã‚¹
                    conf = float(box.conf[0].cpu().numpy())
                    cls = int(box.cls[0].cpu().numpy())
                    
                    # ã‚¯ãƒ©ã‚¹åå–å¾—
                    character_name = self.multiclass_names[cls] if cls < len(self.multiclass_names) else 'unknown'
                    
                    # æ¤œå‡ºçµæœä½œæˆ
                    face_detection = FaceDetection(
                        bbox=(x1, y1, x2, y2),
                        confidence=conf,
                        detection_id=i
                    )
                    
                    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è­˜åˆ¥çµæœä½œæˆï¼ˆãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ã®å ´åˆã¯1.0ã®ç¢ºç‡ã§è©²å½“ã‚¯ãƒ©ã‚¹ï¼‰
                    all_probabilities = {name: 0.0 for name in self.multiclass_names}
                    all_probabilities[character_name] = 1.0
                    
                    character_identification = CharacterIdentification(
                        character_name=character_name,
                        confidence=conf,  # YOLOã®æ¤œå‡ºä¿¡é ¼åº¦ã‚’ãã®ã¾ã¾ä½¿ç”¨
                        all_probabilities=all_probabilities,
                        top_k_predictions=[{'character': character_name, 'confidence': conf}]
                    )
                    
                    # çµæœçµ±åˆ
                    result = FaceCharacterResult(
                        detection=face_detection,
                        identification=character_identification,
                        face_image=None  # ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ã§ã¯é¡”ç”»åƒã¯æŠ½å‡ºã—ãªã„
                    )
                    
                    detections.append(result)
        
        return detections
    
    def detect_faces(self, image: np.ndarray) -> List[FaceDetection]:
        """
        YOLO11xã«ã‚ˆã‚‹é¡”æ¤œå‡º
        
        Args:
            image: å…¥åŠ›ç”»åƒ (BGR)
            
        Returns:
            é¡”æ¤œå‡ºçµæœã®ãƒªã‚¹ãƒˆ
        """
        results = self.yolo_model(
            image, 
            conf=self.detection_conf_threshold, 
            iou=self.detection_iou_threshold,
            verbose=False
        )
        
        detections = []
        detection_id = 0
        
        for r in results:
            if r.boxes is not None:
                for box in r.boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = box.conf[0].cpu().numpy()
                    
                    detection = FaceDetection(
                        bbox=(float(x1), float(y1), float(x2), float(y2)),
                        confidence=float(conf),
                        detection_id=detection_id
                    )
                    detections.append(detection)
                    detection_id += 1
        
        return detections
    
    def extract_face_image(self, image: np.ndarray, detection: FaceDetection) -> np.ndarray:
        """
        é¡”é ˜åŸŸã®æŠ½å‡ºï¼ˆãƒãƒ¼ã‚¸ãƒ³ä»˜ãï¼‰
        
        Args:
            image: å…ƒç”»åƒ
            detection: é¡”æ¤œå‡ºçµæœ
            
        Returns:
            æŠ½å‡ºã•ã‚ŒãŸé¡”ç”»åƒ
        """
        h, w = image.shape[:2]
        x1, y1, x2, y2 = detection.bbox
        
        # ãƒãƒ¼ã‚¸ãƒ³è¨ˆç®—
        margin_x = int((x2 - x1) * self.face_margin)
        margin_y = int((y2 - y1) * self.face_margin)
        
        # å¢ƒç•Œãƒã‚§ãƒƒã‚¯ä»˜ãã§åº§æ¨™è¨ˆç®—
        x1 = max(0, int(x1 - margin_x))
        y1 = max(0, int(y1 - margin_y))
        x2 = min(w, int(x2 + margin_x))
        y2 = min(h, int(y2 + margin_y))
        
        return image[y1:y2, x1:x2]
    
    def identify_character(self, face_image: np.ndarray) -> CharacterIdentification:
        """
        DINOv2ã«ã‚ˆã‚‹ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è­˜åˆ¥
        
        Args:
            face_image: é¡”ç”»åƒ (BGR)
            
        Returns:
            ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è­˜åˆ¥çµæœ
        """
        # PILã‚¤ãƒ¡ãƒ¼ã‚¸ã«å¤‰æ›
        face_pil = Image.fromarray(cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB))
        
        # å‰å‡¦ç†ã¨ãƒ†ãƒ³ã‚½ãƒ«å¤‰æ›
        inputs = self.processor(images=face_pil, return_tensors="pt")
        pixel_values = inputs['pixel_values'].to(self.device)
        
        # æ¨è«–
        with torch.no_grad():
            logits = self.dinov2_model(pixel_values)
            probabilities = torch.nn.functional.softmax(logits, dim=1)[0]
            predicted_idx = torch.argmax(logits, dim=1).item()
            confidence = probabilities[predicted_idx].item()
        
        # çµæœæ•´ç†
        predicted_class = self.class_names[predicted_idx]
        
        # ä¿¡é ¼åº¦ãŒé–¾å€¤ä»¥ä¸‹ã®å ´åˆã¯unknownã¨ã™ã‚‹
        if confidence < self.classification_conf_threshold:
            predicted_class = 'unknown'
        
        # å…¨ã‚¯ãƒ©ã‚¹ã®ç¢ºç‡
        all_probabilities = {
            self.class_names[i]: float(probabilities[i])
            for i in range(len(self.class_names))
        }
        
        # Top-Käºˆæ¸¬
        top_k_indices = torch.topk(probabilities, k=min(3, len(self.class_names))).indices
        top_k_predictions = [
            {
                'class': self.class_names[idx.item()],
                'confidence': float(probabilities[idx.item()])
            }
            for idx in top_k_indices
        ]
        
        return CharacterIdentification(
            character_name=predicted_class,
            confidence=float(confidence),
            all_probabilities=all_probabilities,
            top_k_predictions=top_k_predictions
        )
    
    def process_image(self, image_path: Union[str, Path]) -> ImageProcessingResult:
        """
        ç”»åƒå…¨ä½“ã®å‡¦ç†ï¼ˆæ¤œå‡ºï¼‹è­˜åˆ¥ï¼‰
        
        Args:
            image_path: å…¥åŠ›ç”»åƒãƒ‘ã‚¹
            
        Returns:
            å‡¦ç†çµæœ
        """
        start_time = datetime.now()
        image_path = Path(image_path)
        
        logger.info(f"ç”»åƒå‡¦ç†é–‹å§‹: {image_path.name}")
        
        # ç”»åƒèª­ã¿è¾¼ã¿
        image = cv2.imread(str(image_path))
        if image is None:
            raise ValueError(f"ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—: {image_path}")
        
        h, w = image.shape[:2]
        
        # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦å‡¦ç†åˆ†å²
        if self.multiclass_mode:
            # ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ãƒ¢ãƒ¼ãƒ‰ï¼šYOLOã§ç›´æ¥ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ¤œå‡º
            logger.info("ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ãƒ¢ãƒ¼ãƒ‰ã§å‡¦ç†ä¸­...")
            results = self.detect_multiclass_characters(image)
            
            # æ¤œå‡ºã•ã‚ŒãŸå…¨ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®è©³ç´°è¡¨ç¤º
            detected_chars = []
            for result in results:
                char_name = result.identification.character_name
                confidence = result.identification.confidence
                detected_chars.append(f"{char_name}({confidence:.3f})")
                self.stats['character_counts'][char_name] = self.stats['character_counts'].get(char_name, 0) + 1
                logger.debug(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ {result.detection.detection_id}: {char_name} (ä¿¡é ¼åº¦: {confidence:.3f})")
            
            logger.info(f"ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹æ¤œå‡ºå®Œäº†: {len(results)}äºº (ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰) - [{', '.join(detected_chars)}]")
        else:
            # å¾“æ¥ãƒ¢ãƒ¼ãƒ‰ï¼šé¡”æ¤œå‡ºâ†’èªè­˜ã®2æ®µéš
            logger.info("é¡”æ¤œå‡º+èªè­˜ãƒ¢ãƒ¼ãƒ‰ã§å‡¦ç†ä¸­...")
            
            # é¡”æ¤œå‡º
            detections = self.detect_faces(image)
            logger.info(f"æ¤œå‡ºé¡”æ•°: {len(detections)}")
            
            # å„é¡”ã‚’è­˜åˆ¥
            results = []
            for detection in detections:
                try:
                    # é¡”ç”»åƒæŠ½å‡º
                    face_image = self.extract_face_image(image, detection)
                    
                    if face_image.size == 0:
                        logger.warning(f"é¡”ç”»åƒæŠ½å‡ºå¤±æ•—: ID {detection.detection_id}")
                        continue
                    
                    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è­˜åˆ¥
                    identification = self.identify_character(face_image)
                    
                    # çµæœä½œæˆ
                    result = FaceCharacterResult(
                        detection=detection,
                        identification=identification,
                        face_image=face_image
                    )
                    results.append(result)
                    
                    # çµ±è¨ˆæ›´æ–°
                    char_name = identification.character_name
                    self.stats['character_counts'][char_name] = self.stats['character_counts'].get(char_name, 0) + 1
                    
                    logger.debug(f"é¡” {detection.detection_id}: {char_name} (ä¿¡é ¼åº¦: {identification.confidence:.3f})")
                    
                except Exception as e:
                    logger.warning(f"è­˜åˆ¥ã‚¨ãƒ©ãƒ¼ (ID: {detection.detection_id}): {e}")
                    continue
            
            logger.info(f"é¡”æ¤œå‡º+èªè­˜å®Œäº†: {len(results)}äººè­˜åˆ¥")
        
        # é‡è¤‡é™¤å»å‡¦ç†
        if len(results) > 1:
            original_count = len(results)
            logger.debug(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–‹å§‹: {original_count}äºº")
            
            # IoUãƒ™ãƒ¼ã‚¹é‡è¤‡é™¤å»
            after_iou = self._remove_duplicate_detections(results, iou_threshold=0.3)
            if len(after_iou) != len(results):
                logger.debug(f"IoUé‡è¤‡é™¤å»: {len(results)}äºº â†’ {len(after_iou)}äºº")
            results = after_iou
            
            # æ—¥å‘ç¸ãƒ»å²¡é‡ä½³ã®é‡è¤‡æ¤œå‡ºãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            after_yukari_kei = self._filter_yukari_kei_duplicates(results)
            if len(after_yukari_kei) != len(results):
                logger.debug(f"æ—¥å‘ç¸ãƒ»å²¡é‡ä½³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: {len(results)}äºº â†’ {len(after_yukari_kei)}äºº")
            results = after_yukari_kei
            
            # åŒä¸€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é‡è¤‡é™¤å»
            final_results = self._filter_same_character_duplicates(results)
            if len(final_results) != len(results):
                logger.debug(f"åŒä¸€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é‡è¤‡é™¤å»: {len(results)}äºº â†’ {len(final_results)}äºº")
            results = final_results
            
            if len(results) != original_count:
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®æœ€çµ‚çµæœè©³ç´°è¡¨ç¤º
                final_chars = [f"{r.identification.character_name}({r.identification.confidence:.3f})" for r in results]
                logger.info(f"é‡è¤‡é™¤å»å®Œäº†: {original_count}äºº â†’ {len(results)}äºº (ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œ) - [{', '.join(final_chars)}]")
        
        # å‡¦ç†æ™‚é–“è¨ˆç®—
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # çµæœä½œæˆ
        processing_result = ImageProcessingResult(
            image_path=str(image_path),
            image_size=(w, h),
            results=results,
            processing_time=processing_time,
            timestamp=datetime.now().isoformat()
        )
        
        # çµ±è¨ˆæ›´æ–°
        self.stats['total_images'] += 1
        self.stats['total_faces'] += len(results)  # ä¿®æ­£: detectionsã§ã¯ãªãresultsã‚’ä½¿ç”¨
        self.stats['total_identifications'] += len(results)
        self.stats['processing_times'].append(processing_time)
        
        logger.info(f"å‡¦ç†å®Œäº†: {len(results)}äººè­˜åˆ¥ ({processing_time:.2f}ç§’)")
        
        return processing_result
    
    def visualize_results(
        self,
        image_path: Union[str, Path],
        result: ImageProcessingResult,
        output_path: Optional[Union[str, Path]] = None,
        show: bool = False,
        use_character_colors: bool = True
    ) -> np.ndarray:
        """
        çµæœã®å¯è¦–åŒ–
        
        Args:
            image_path: å…ƒç”»åƒãƒ‘ã‚¹
            result: å‡¦ç†çµæœ
            output_path: ä¿å­˜å…ˆãƒ‘ã‚¹
            show: è¡¨ç¤ºã™ã‚‹ã‹
            use_character_colors: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¥è‰²ã‚’ä½¿ç”¨ã™ã‚‹ã‹
            
        Returns:
            æç”»æ¸ˆã¿ç”»åƒ
        """
        # ç”»åƒèª­ã¿è¾¼ã¿
        image = cv2.imread(str(image_path))
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
        fig, ax = plt.subplots(1, 1, figsize=(12, 8))
        ax.imshow(image_rgb)
        
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
        try:
            font_path = '/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W3.ttc'
            if Path(font_path).exists():
                prop = font_manager.FontProperties(fname=font_path)
                plt.rcParams['font.family'] = prop.get_name()
        except:
            pass
        
        # é‡è¤‡é™¤å»å¾Œã®çµæœã‚’æç”»
        for i, face_result in enumerate(result.results):
            x1, y1, x2, y2 = face_result.detection.bbox
            character = face_result.identification.character_name
            char_conf = face_result.identification.confidence
            det_conf = face_result.detection.confidence
            
            # è‰²ã®é¸æŠï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¥ï¼‰
            if use_character_colors:
                color_rgb = self.CHARACTER_COLORS.get(character, self.CHARACTER_COLORS['unknown'])
                color = tuple(c/255.0 for c in color_rgb)
            else:
                # ä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹ã®è‰²
                if char_conf >= 0.8:
                    color = 'green'
                elif char_conf >= 0.6:
                    color = 'yellow'
                else:
                    color = 'red'
            
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ï¼ˆå¤ªç·šï¼‰
            rect = patches.Rectangle(
                (x1, y1), x2-x1, y2-y1,
                linewidth=4, edgecolor=color, facecolor='none'
            )
            ax.add_patch(rect)
            
            # ç°¡æ½”ãªãƒ©ãƒ™ãƒ«è¡¨ç¤ºï¼ˆå†…å´ã«ï¼‰
            # ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯æ¤œå‡ºä¿¡é ¼åº¦ã€å¾“æ¥ãƒ¢ãƒ¼ãƒ‰ã¯è­˜åˆ¥ä¿¡é ¼åº¦ã‚’é‡è¦–
            main_conf = char_conf if not self.multiclass_mode else det_conf
            label = f'{character} ({main_conf:.1%})'
            
            # ãƒ©ãƒ™ãƒ«ã‚’å†…å´ã®é©åˆ‡ãªä½ç½®ã«é…ç½®
            bbox_width = x2 - x1
            bbox_height = y2 - y1
            text_x = x1 + bbox_width * 0.02  # å·¦ç«¯ã‹ã‚‰å°‘ã—å†…å´
            text_y = y1 + bbox_height * 0.95  # ä¸‹ç«¯è¿‘ã
            
            ax.text(
                text_x, text_y, label,
                color='white', fontsize=12, weight='bold',
                bbox=dict(boxstyle='round,pad=0.3', facecolor=color, alpha=0.8, edgecolor='white', linewidth=1),
                verticalalignment='bottom'
            )
        
        ax.axis('off')
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã«ãƒ¢ãƒ¼ãƒ‰æƒ…å ±ã‚’å«ã‚ã‚‹
        mode_str = "ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹æ¤œå‡º" if self.multiclass_mode else "é¡”æ¤œå‡º+èªè­˜"
        character_list = ", ".join(result.get_character_counts().keys()) if result.get_character_counts() else "ãªã—"
        title = f'{mode_str} | æ¤œå‡º: {len(result.results)}äºº | ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: {character_list}'
        ax.set_title(title, fontsize=14, weight='bold')
        
        plt.tight_layout()
        
        if output_path:
            plt.savefig(output_path, bbox_inches='tight', dpi=150)
            logger.info(f"å¯è¦–åŒ–ç”»åƒä¿å­˜: {output_path}")
        
        if show:
            plt.show()
        
        # numpyé…åˆ—ã¨ã—ã¦è¿”ã™ï¼ˆMacäº’æ›æ€§ã‚’è€ƒæ…®ï¼‰
        fig.canvas.draw()
        
        # BufferIOã‚’ä½¿ç”¨ã—ã¦PNGå½¢å¼ã§ç”»åƒã‚’å–å¾—
        import io
        from PIL import Image
        buf = io.BytesIO()
        plt.savefig(buf, format='png', bbox_inches='tight', dpi=100)
        buf.seek(0)
        
        # PILã§èª­ã¿è¾¼ã‚“ã§numpyé…åˆ—ã«å¤‰æ›
        pil_image = Image.open(buf)
        img_array = np.array(pil_image)
        
        plt.close()
        buf.close()
        
        # RGBå½¢å¼ã«å¤‰æ›ï¼ˆé€æ˜åº¦ãƒãƒ£ãƒ³ãƒãƒ«ã‚’é™¤å»ï¼‰
        if img_array.shape[-1] == 4:  # RGBA
            img_array = img_array[:, :, :3]  # RGB
        
        return img_array
    
    def process_batch(
        self,
        image_paths: List[Union[str, Path]],
        show_progress: bool = True
    ) -> List[ImageProcessingResult]:
        """
        ãƒãƒƒãƒå‡¦ç†
        
        Args:
            image_paths: ç”»åƒãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
            show_progress: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
            
        Returns:
            å‡¦ç†çµæœã®ãƒªã‚¹ãƒˆ
        """
        results = []
        
        if show_progress:
            image_paths = tqdm(image_paths, desc="ç”»åƒå‡¦ç†ä¸­")
        
        for image_path in image_paths:
            try:
                result = self.process_image(image_path)
                results.append(result)
            except Exception as e:
                logger.error(f"ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼ {image_path}: {e}")
                continue
        
        return results
    
    def process_directory(
        self,
        directory: Union[str, Path],
        extensions: List[str] = ['.jpg', '.jpeg', '.png', '.bmp'],
        recursive: bool = False,
        max_images: Optional[int] = None
    ) -> List[ImageProcessingResult]:
        """
        ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€æ‹¬å‡¦ç†
        
        Args:
            directory: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
            extensions: å¯¾è±¡æ‹¡å¼µå­
            recursive: å†å¸°çš„æ¤œç´¢
            max_images: æœ€å¤§å‡¦ç†ç”»åƒæ•°
            
        Returns:
            å‡¦ç†çµæœã®ãƒªã‚¹ãƒˆ
        """
        directory = Path(directory)
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åé›†
        image_files = []
        for ext in extensions:
            if recursive:
                image_files.extend(directory.rglob(f"*{ext}"))
                image_files.extend(directory.rglob(f"*{ext.upper()}"))
            else:
                image_files.extend(directory.glob(f"*{ext}"))
                image_files.extend(directory.glob(f"*{ext.upper()}"))
        
        # é‡è¤‡é™¤å»ã¨ã‚½ãƒ¼ãƒˆ
        image_files = sorted(list(set(image_files)))
        
        if max_images and len(image_files) > max_images:
            image_files = image_files[:max_images]
        
        logger.info(f"å‡¦ç†å¯¾è±¡: {len(image_files)}æš")
        
        return self.process_batch(image_files)
    
    def save_results(
        self,
        results: List[ImageProcessingResult],
        output_dir: Union[str, Path],
        save_format: str = 'json'
    ):
        """
        çµæœã®ä¿å­˜
        
        Args:
            results: å‡¦ç†çµæœã®ãƒªã‚¹ãƒˆ
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            save_format: ä¿å­˜å½¢å¼ ('json' or 'csv')
        """
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if save_format == 'json':
            # JSONä¿å­˜
            output_data = {
                'pipeline_info': {
                    'timestamp': timestamp,
                    'total_images': len(results),
                    'class_names': self.class_names,
                    'statistics': self.get_statistics()
                },
                'results': [r.to_dict() for r in results]
            }
            
            output_path = output_dir / f"results_{timestamp}.json"
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"çµæœä¿å­˜: {output_path}")
            
        elif save_format == 'csv':
            # CSVä¿å­˜
            import pandas as pd
            
            csv_rows = []
            for result in results:
                for face_result in result.results:
                    row = {
                        'image_path': result.image_path,
                        'image_width': result.image_size[0],
                        'image_height': result.image_size[1],
                        'face_id': face_result.detection.detection_id,
                        'x1': face_result.detection.bbox[0],
                        'y1': face_result.detection.bbox[1],
                        'x2': face_result.detection.bbox[2],
                        'y2': face_result.detection.bbox[3],
                        'detection_confidence': face_result.detection.confidence,
                        'character': face_result.identification.character_name,
                        'character_confidence': face_result.identification.confidence,
                        'processing_time': result.processing_time
                    }
                    
                    # å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ç¢ºç‡ã‚’è¿½åŠ 
                    for char, prob in face_result.identification.all_probabilities.items():
                        row[f'prob_{char}'] = prob
                    
                    csv_rows.append(row)
            
            df = pd.DataFrame(csv_rows)
            output_path = output_dir / f"results_{timestamp}.csv"
            df.to_csv(output_path, index=False)
            
            logger.info(f"CSVä¿å­˜: {output_path}")
    
    def get_statistics(self) -> Dict:
        """çµ±è¨ˆæƒ…å ±ã®å–å¾—"""
        stats = self.stats.copy()
        
        if stats['processing_times']:
            stats['avg_processing_time'] = np.mean(stats['processing_times'])
            stats['total_processing_time'] = sum(stats['processing_times'])
        else:
            stats['avg_processing_time'] = 0.0
            stats['total_processing_time'] = 0.0
        
        # æˆåŠŸç‡
        if stats['total_faces'] > 0:
            stats['identification_rate'] = stats['total_identifications'] / stats['total_faces']
        else:
            stats['identification_rate'] = 0.0
        
        return stats
    
    def print_statistics(self):
        """çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º"""
        stats = self.get_statistics()
        
        print("\n" + "="*60)
        print("YOLO11x + DINOv2 ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±è¨ˆ")
        print("="*60)
        print(f"å‡¦ç†ç”»åƒæ•°: {stats['total_images']}")
        print(f"æ¤œå‡ºé¡”æ•°: {stats['total_faces']}")
        print(f"è­˜åˆ¥æˆåŠŸæ•°: {stats['total_identifications']}")
        print(f"è­˜åˆ¥ç‡: {stats['identification_rate']:.1%}")
        print(f"å¹³å‡å‡¦ç†æ™‚é–“: {stats['avg_processing_time']:.2f}ç§’/æš")
        print(f"ç·å‡¦ç†æ™‚é–“: {stats['total_processing_time']:.2f}ç§’")
        
        if stats['character_counts']:
            print(f"\nã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¥æ¤œå‡ºæ•°:")
            for char, count in sorted(stats['character_counts'].items(), 
                                     key=lambda x: x[1], reverse=True):
                print(f"  {char}: {count}äºº")
        print("="*60)


def main():
    """ãƒ‡ãƒ¢å®Ÿè¡Œ"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='YOLO11x + DINOv2 çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('--yolo_model',
                        default='/Users/esuji/work/fun_annotator/yolo11x_face_detection_model/yolo11l_480_12_14.pt',
                        help='YOLOãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--dinov2_model',
                        default='/Users/esuji/work/fun_annotator/yuyu_dinov2_final.pth',
                        help='DINOv2ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--input',
                        required=True,
                        help='å…¥åŠ›ç”»åƒã¾ãŸã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--output_dir',
                        default='./pipeline_output',
                        help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--device',
                        choices=['auto', 'cpu', 'cuda'],
                        default='auto',
                        help='ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹')
    parser.add_argument('--detection_conf',
                        type=float,
                        default=0.25,
                        help='æ¤œå‡ºä¿¡é ¼åº¦é–¾å€¤')
    parser.add_argument('--classification_conf',
                        type=float,
                        default=0.5,
                        help='åˆ†é¡ä¿¡é ¼åº¦é–¾å€¤')
    parser.add_argument('--visualize',
                        action='store_true',
                        help='çµæœã‚’å¯è¦–åŒ–')
    parser.add_argument('--save_format',
                        choices=['json', 'csv'],
                        default='json',
                        help='ä¿å­˜å½¢å¼')
    parser.add_argument('--max_images',
                        type=int,
                        help='æœ€å¤§å‡¦ç†ç”»åƒæ•°')
    
    args = parser.parse_args()
    
    try:
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–
        pipeline = YuyuYOLODINOv2Pipeline(
            yolo_model_path=args.yolo_model,
            dinov2_model_path=args.dinov2_model,
            device=args.device,
            detection_conf_threshold=args.detection_conf,
            classification_conf_threshold=args.classification_conf
        )
        
        # å…¥åŠ›ãƒ‘ã‚¹ç¢ºèª
        input_path = Path(args.input)
        
        if input_path.is_file():
            # å˜ä¸€ç”»åƒå‡¦ç†
            print(f"\nå˜ä¸€ç”»åƒå‡¦ç†: {input_path}")
            result = pipeline.process_image(input_path)
            results = [result]
            
            # çµæœè¡¨ç¤º
            print(f"\nå‡¦ç†çµæœ:")
            print(f"  æ¤œå‡ºé¡”æ•°: {len(result.results)}")
            print(f"  ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: {result.get_character_counts()}")
            print(f"  å‡¦ç†æ™‚é–“: {result.processing_time:.2f}ç§’")
            
        elif input_path.is_dir():
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‡¦ç†
            print(f"\nãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‡¦ç†: {input_path}")
            results = pipeline.process_directory(
                input_path,
                max_images=args.max_images
            )
            
        else:
            raise ValueError(f"å…¥åŠ›ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}")
        
        # çµæœä¿å­˜
        output_dir = Path(args.output_dir)
        pipeline.save_results(results, output_dir, save_format=args.save_format)
        
        # å¯è¦–åŒ–
        if args.visualize:
            vis_dir = output_dir / 'visualizations'
            vis_dir.mkdir(parents=True, exist_ok=True)
            
            print("\nå¯è¦–åŒ–ä½œæˆä¸­...")
            for result in tqdm(results[:10], desc="å¯è¦–åŒ–"):  # æœ€å¤§10æš
                if len(result.results) > 0:
                    image_path = Path(result.image_path)
                    vis_path = vis_dir / f"{image_path.stem}_vis.jpg"
                    pipeline.visualize_results(
                        image_path,
                        result,
                        output_path=vis_path
                    )
        
        # çµ±è¨ˆè¡¨ç¤º
        pipeline.print_statistics()
        
        print(f"\nå®Œäº†ï¼çµæœã¯ {output_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
        
    except Exception as e:
        logger.error(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())