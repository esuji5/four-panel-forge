import json
import os
from collections import defaultdict
from typing import List, Dict, Any, Optional
from datetime import datetime
import hashlib
from pathlib import Path
from difflib import SequenceMatcher
import copy
import sys

import pandas as pd
from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel

from llm_utils import (
    build_koma_id,
    fetch_anthropic_4koma_response,
    fetch_anthropic_discussion_response,
    fetch_gemini_4koma_response,
    fetch_gemini_discussion_response,
    fetch_gemini_response,
    fetch_gemini_response_base64,
    fetch_gemini_response_multimodal,
    LLMManager,
    LLMConfig,
)
from balloon_detection_integration import get_balloon_detector, integrate_balloon_detection, draw_tail_shape_results_on_image

# ãƒ‡ãƒãƒƒã‚°ç”¨ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«
class DebugResponse(BaseModel):
    message: str
    pipeline_available: bool
    visualize_method_available: bool
    test_result: str
import base64
import io
from PIL import Image
import cv2
import numpy as np

# forceAPIç”¨ã®ç›´æ¥APIå‘¼ã³å‡ºã—é–¢æ•°
def fetch_gemini_response_base64_direct_api(prompt, base64_image, original_image_path=None):
    """forceAPIç”¨: Gemini APIç›´æ¥å‘¼ã³å‡ºã—"""
    from datetime import datetime
    import json
    import base64 as b64
    import requests
    
    model = "gemini-2.5-flash-preview-05-20"
    log_with_time(f"start fetch_gemini_response_base64_direct_api with {model}", level="INFO")
    
    # è¨­å®šã‹ã‚‰ API ã‚­ãƒ¼ã‚’å–å¾—
    llm_manager = LLMManager()
    config = llm_manager.config
    
    # ãƒ‡ãƒãƒƒã‚°: APIã‚­ãƒ¼ã®ç¢ºèª
    api_key = config.google_api_key
    env_api_key = os.getenv("GOOGLE_API_KEY")
    log_with_time(f"ğŸ”‘ è¨­å®šAPIã‚­ãƒ¼: {api_key[:20]}..." if api_key else "ğŸ”‘ è¨­å®šAPIã‚­ãƒ¼ãªã—", level="DEBUG")
    log_with_time(f"ğŸ”‘ ç’°å¢ƒå¤‰æ•°APIã‚­ãƒ¼: {env_api_key[:20]}..." if env_api_key else "ğŸ”‘ ç’°å¢ƒå¤‰æ•°APIã‚­ãƒ¼ãªã—", level="DEBUG")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    query_dir = f"tmp/api_queries/gemini_direct_api_{timestamp}"
    os.makedirs(query_dir, exist_ok=True)

    # APIã‚­ãƒ¼ã‚’å–å¾—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–¹å¼ï¼‰ - ä¸€æ™‚çš„ã«ç›´æ¥æŒ‡å®š
    final_api_key = "AIzaSyC9DUiCaiNINeoOiI1YDIqVWrSIFfVVBBs"
    log_with_time(f"ğŸ”‘ æœ€çµ‚ä½¿ç”¨APIã‚­ãƒ¼: {final_api_key[:20]}...", level="DEBUG")
    log_with_time(f"ğŸ”‘ å®Œå…¨ãªAPIã‚­ãƒ¼: {final_api_key}", level="DEBUG")

    # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
    log_with_time(f"ğŸ–¼ï¸ å—ä¿¡ã—ãŸbase64_imageé•·ã•: {len(base64_image) if base64_image else 0}", level="DEBUG")
    log_with_time(f"ğŸ–¼ï¸ base64_imageå…ˆé ­50æ–‡å­—: {base64_image[:50] if base64_image else 'None'}", level="DEBUG")
    
    # base64_imageãŒdata:image/jpeg;base64,ã§å§‹ã¾ã‚‹å ´åˆã¯å‰Šé™¤
    if base64_image.startswith("data:image"):
        log_with_time("ğŸ–¼ï¸ data:image ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»", level="DEBUG")
        base64_image = base64_image.split(",")[1]
        log_with_time(f"ğŸ–¼ï¸ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹é™¤å»å¾Œã®é•·ã•: {len(base64_image)}", level="DEBUG")

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿å­˜ï¼ˆç©ºã®å ´åˆã®è­¦å‘Šä»˜ãï¼‰
    if not prompt or prompt.strip() == "":
        log_with_time("âš ï¸ è­¦å‘Š: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒç©ºã§ã™", level="WARNING")
        log_with_time(f"ğŸ” å—ä¿¡ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¼•æ•°: '{prompt}'", level="DEBUG")
        prompt_to_save = "# WARNING: Empty prompt received\n"
    else:
        prompt_to_save = prompt
        log_with_time(f"âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿å­˜: é•·ã•={len(prompt_to_save)}, æœ€åˆã®200æ–‡å­—={prompt_to_save[:200]}", level="DEBUG")
        
    with open(f"{query_dir}/prompt.txt", "w", encoding="utf-8") as f:
        f.write(prompt_to_save)

    # ç”»åƒã‚’ä¿å­˜ï¼ˆBase64ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦ä¿å­˜ï¼‰
    try:
        image_data = b64.b64decode(base64_image)
        log_with_time(f"ğŸ–¼ï¸ ç”»åƒãƒ‡ã‚³ãƒ¼ãƒ‰æˆåŠŸ: {len(image_data)} bytes", level="DEBUG")
        with open(f"{query_dir}/image.jpg", "wb") as f:
            f.write(image_data)
        log_with_time(f"ğŸ–¼ï¸ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {query_dir}/image.jpg", level="DEBUG")
    except Exception as e:
        log_with_time(f"âŒ ç”»åƒãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}", level="ERROR")
        raise

    # ã‚¯ã‚¨ãƒªæƒ…å ±ã‚’ä¿å­˜
    query_info = {
        "model": model,
        "timestamp": timestamp,
        "prompt_length": len(prompt),
        "prompt_preview": prompt[:100] if prompt else "EMPTY",
        "prompt_is_empty": not prompt or prompt.strip() == "",
        "base64_length": len(base64_image),
        "image_size": len(image_data),
        "original_image_path": original_image_path,
        "force_api": True,
    }
    with open(f"{query_dir}/query_info.json", "w", encoding="utf-8") as f:
        json.dump(query_info, f, ensure_ascii=False, indent=2)

    log_with_time(f"Query saved to: {query_dir}", level="INFO")

    # CombinedKomaPromptTesterã¨åŒã˜æ–¹å¼ã§HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={final_api_key}"
    
    headers = {
        "Content-Type": "application/json",
    }
    
    payload = {
        "contents": [
            {
                "parts": [
                    {"text": prompt},
                    {
                        "inline_data": {
                            "mime_type": "image/jpeg",
                            "data": base64_image,
                        },
                    },
                ],
            },
        ],
    }

    log_with_time(f"ğŸŒ HTTP Request to: {url[:80]}...", level="DEBUG")
    log_with_time(f"ğŸŒ Full URL: {url}", level="DEBUG")
    log_with_time(f"ğŸŒ Headers: {headers}", level="DEBUG")
    log_with_time(f"ğŸŒ Payload keys: {list(payload.keys())}", level="DEBUG")
    log_with_time(f"ğŸŒ Payload parts count: {len(payload['contents'][0]['parts'])}", level="DEBUG")
    log_with_time(f"ğŸŒ Payload text part length: {len(payload['contents'][0]['parts'][0]['text'])}", level="DEBUG")
    log_with_time(f"ğŸŒ Payload text part preview: {payload['contents'][0]['parts'][0]['text'][:100]}...", level="DEBUG")
    log_with_time(f"ğŸŒ Payload image data length: {len(payload['contents'][0]['parts'][1]['inline_data']['data'])}", level="DEBUG")
    log_with_time(f"ğŸŒ Payload image mime_type: {payload['contents'][0]['parts'][1]['inline_data']['mime_type']}", level="DEBUG")
    
    response = requests.post(url, headers=headers, json=payload)
    
    if not response.ok:
        log_with_time(f"âŒ HTTP Error: {response.status_code} - {response.text}", level="ERROR")
        raise Exception(f"Gemini API error: {response.status_code} - {response.text}")

    response_data = response.json()
    log_with_time("âœ… HTTP Request successful", level="DEBUG")
    
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜
    with open(f"{query_dir}/response.json", "w", encoding="utf-8") as f:
        json.dump(response_data, f, ensure_ascii=False, indent=2)
    
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚‚ä¿å­˜
    if "candidates" in response_data and len(response_data["candidates"]) > 0:
        response_text = response_data["candidates"][0]["content"]["parts"][0]["text"]
        with open(f"{query_dir}/response.txt", "w", encoding="utf-8") as f:
            f.write(response_text)
        log_with_time(f"ğŸ’¾ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¿å­˜å®Œäº†: {query_dir}/response.json, response.txt", level="DEBUG")
    else:
        log_with_time("âš ï¸ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«candidatesãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“", level="WARNING")
    
    # SDKã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã«åˆã‚ã›ã¦è¿”ã™
    class MockResponse:
        def __init__(self, data):
            self.text = data["candidates"][0]["content"]["parts"][0]["text"]
    
    return MockResponse(response_data)

# ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ­ã‚°é–¢æ•°
def log_with_time(message: str, level: str = "INFO"):
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã§ãƒ­ã‚°ã‚’å‡ºåŠ›"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
    prefix = {
        "INFO": "â„¹ï¸",
        "DEBUG": "ğŸ”",
        "ERROR": "âŒ",
        "WARNING": "âš ï¸",
        "SUCCESS": "âœ…"
    }.get(level, "ğŸ“")
    
    log_message = f"[{timestamp}] {prefix} {message}"
    print(log_message)
    sys.stdout.flush()  # å³åº§ã«å‡ºåŠ›ã‚’åæ˜ 

# YOLO+DINOv2æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from yuyu_yolo_dinov2_pipeline import YuyuYOLODINOv2Pipeline
    yolo_dinov2_pipeline = None
    current_detection_mode = "multiclass"  # "face_recognition" or "multiclass"
except ImportError as e:
    log_with_time(f"YOLO+DINOv2ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}", "WARNING")
    yolo_dinov2_pipeline = None
    current_detection_mode = "multiclass"

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å¿…è¦ã«å¿œã˜ã¦ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’æŒ‡å®š
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# YOLO+DINOv2ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åˆæœŸåŒ–
@app.on_event("startup")
async def startup_event():
    global yolo_dinov2_pipeline, current_detection_mode
    try:
        log_with_time("YOLO+DINOv2ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ä¸­...", level="INFO")
        yolo_dinov2_pipeline = YuyuYOLODINOv2Pipeline()
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š
        yolo_dinov2_pipeline.set_mode(True)  # True = ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰
        current_detection_mode = "multiclass"
        log_with_time("YOLO+DINOv2ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–å®Œäº†ï¼ˆãƒãƒ«ãƒã‚¯ãƒ©ã‚¹æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ï¼‰", level="SUCCESS")
    except Exception as e:
        log_with_time(f"YOLO+DINOv2ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}", level="ERROR")
        yolo_dinov2_pipeline = None


def get_yuyu_pipeline():
    """YOLO+DINOv2ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    global yolo_dinov2_pipeline
    return yolo_dinov2_pipeline


class ImageData(BaseModel):
    dataName: str
    currentIndex: int
    komaPath: str
    imageData: dict
    summary: str




class CombinedImageData(BaseModel):
    komaPath: str  # Base64ç”»åƒãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    originalImagePath: str = None  # å…ƒã®ç”»åƒãƒ‘ã‚¹ï¼ˆçµåˆå‰ï¼‰
    prompt: str = None  # å¾“æ¥ã®æ–‡å­—åˆ—ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
    promptMessages: list = None  # é…åˆ—å½¢å¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œï¼‰
    mode: str = "combined-four-panel"
    forceAPI: bool = False  # APIå¼·åˆ¶ä½¿ç”¨ãƒ•ãƒ©ã‚°
    useMultiModal: bool = False  # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ä½¿ç”¨ãƒ•ãƒ©ã‚°
    enableBalloonDetection: bool = True  # å¹ãå‡ºã—æ¤œå‡ºãƒ•ãƒ©ã‚°
    imagePathList: dict = None  # 4ã‚³ãƒå€‹åˆ¥ç”»åƒãƒ‘ã‚¹ï¼ˆå¹ãå‡ºã—æ¤œå‡ºç”¨ï¼‰
    enableVisualization: bool = False  # ç”»åƒå¯è¦–åŒ–ãƒ•ãƒ©ã‚°ï¼ˆå°»å°¾å½¢çŠ¶åˆ†é¡çµæœã‚’ç”»åƒä¸Šã«è¡¨ç¤ºï¼‰
    detectionResults: dict = None  # AIæ¤œå‡ºçµæœï¼ˆæ”¹å–„ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ï¼‰
    detectOnly: bool = False  # æ¤œå‡ºãƒ»åˆ†é¡ãƒ»å¯è¦–åŒ–ã®ã¿å®Ÿè¡Œï¼ˆGeminiå‘¼ã³å‡ºã—ãªã—ï¼‰
    detectionMode: str = None  # æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ ("face_recognition" or "multiclass")


class FeedbackRequest(BaseModel):
    dataName: str
    currentIndex: int
    imageData: dict
    imagePathList: dict


class DiscussionRequest(BaseModel):
    dataName: str
    currentIndex: int
    imageData: dict
    imagePathList: dict
    summary: str
    question: str


class YoloDinov2DetectionRequest(BaseModel):
    """YOLO+DINOv2æ¤œå‡ºãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    komaPath: str  # ç”»åƒãƒ‘ã‚¹ã¾ãŸã¯Base64ãƒ‡ãƒ¼ã‚¿
    mode: str = "single"  # "single" ã¾ãŸã¯ "four-panel"
    detectionThreshold: float = 0.25
    classificationThreshold: float = 0.5
    visualize: bool = False  # å¯è¦–åŒ–ãƒ•ãƒ©ã‚°
    detectionMode: str = None  # æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ ("face_recognition" or "multiclass")



class AIProposal(BaseModel):
    """AIææ¡ˆãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ç”¨ãƒ¢ãƒ‡ãƒ«"""
    image_path: str
    timestamp: str
    model: str
    proposal: dict
    confidence_scores: Optional[Dict[str, float]] = None
    processing_time: Optional[float] = None
    api_cost: Optional[float] = None


class RevisionEntry(BaseModel):
    """ä¿®æ­£å±¥æ­´ã®ã‚¨ãƒ³ãƒˆãƒª"""
    timestamp: str
    revision_type: str  # "ai_proposal", "human_edit", "auto_save"
    changes: List[Dict[str, Any]]  # å„å¤‰æ›´ã®è©³ç´°
    editor: str  # "ai", "human"
    confidence: Optional[float] = None
    notes: Optional[str] = None


class RevisionHistory(BaseModel):
    """ä¿®æ­£å±¥æ­´å…¨ä½“"""
    image_path: str
    created_at: str
    last_updated: str
    total_revisions: int
    ai_proposals: List[AIProposal]
    revisions: List[RevisionEntry]
    current_data: dict


class DiffAnalysis(BaseModel):
    """å·®åˆ†åˆ†æçµæœ"""
    field_path: str  # e.g., "characters.0.name"
    old_value: Any
    new_value: Any
    change_type: str  # "added", "modified", "deleted"
    similarity: Optional[float] = None


class DetectionModeRequest(BaseModel):
    """æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    mode: str  # "face_recognition" or "multiclass"


class DetectionModeResponse(BaseModel):
    """æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    success: bool
    current_mode: str
    message: str


@app.post("/api/discussion-claude")
async def get_discussion(request: DiscussionRequest):
    # ã“ã“ã§LLMã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã—ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å–å¾—ã™ã‚‹å‡¦ç†ã‚’å®Ÿè£…
    log_with_time(f"Discussion request (Claude): {request}", level="DEBUG")
    prompt = (
        "ä»Šã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã“ã®æ¼«ç”»ã«ã¤ã„ã¦ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã—ã¾ã—ã‚‡ã†ã€‚è³ªå•ã¯ã“ã¡ã‚‰ã§ã™ï¼š"
        + request.question
    )
    # import pdb;pdb.set_trace()
    summary = json.loads(request.summary)
    response = fetch_anthropic_discussion_response(prompt, summary, request.imageData)
    # with open(f'public/saved_json/discussion_{request.dataName}_{request.currentIndex}.json', 'a+') as f:
    #     f.write(json.dumps(response.json()))

    # æ—¢å­˜ã®å†…å®¹ã‚’ãƒªã‚¹ãƒˆã¨ã—ã¦å–å¾—
    existing_data = []
    try:
        with open(
            f"public/saved_json/discussion_{request.dataName}_{request.currentIndex}.json",
            "r",
        ) as f:
            existing_data = json.load(f)
    except FileNotFoundError:
        pass  # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦ä½œæˆ
    existing_data.append({"user": request.question})
    existing_data.append(response.json())
    # æ›´æ–°ã•ã‚ŒãŸãƒªã‚¹ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€
    with open(
        f"public/saved_json/discussion_{request.dataName}_{request.currentIndex}.json",
        "w",
    ) as f:
        json.dump(existing_data, f, ensure_ascii=False, indent=2)

    return JSONResponse(content=response.json())


@app.post("/api/delete-json")
async def delete_json_files(data: dict):
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
    try:
        data_name = data.get("dataName", "yuyu10")
        current_index = data.get("currentIndex", 0)
        
        files_to_delete = [
            f"public/saved_json/imageData_{data_name}_{current_index}.json",
            f"public/saved_json/feedback_{data_name}_{current_index}.json",
            f"public/saved_json/discussion_{data_name}_{current_index}.json",
            f"public/saved_json/chat_history_{data_name}_{current_index}.json",
            f"public/ai_proposals/proposal_{data_name}_{current_index}_*.json",
            f"public/revision_history/revision_{data_name}_{current_index}_*.json"
        ]
        
        deleted_files = []
        for file_pattern in files_to_delete:
            if "*" in file_pattern:
                # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å ´åˆ
                import glob
                matching_files = glob.glob(file_pattern)
                for file_path in matching_files:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                        deleted_files.append(file_path)
                        log_with_time(f"Deleted file: {file_path}", level="INFO")
            else:
                # é€šå¸¸ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å ´åˆ
                if os.path.exists(file_pattern):
                    os.remove(file_pattern)
                    deleted_files.append(file_pattern)
                    log_with_time(f"Deleted file: {file_pattern}", level="INFO")
        
        return JSONResponse(content={
            "status": "success",
            "deleted_files": deleted_files,
            "message": f"Deleted {len(deleted_files)} files"
        })
        
    except Exception as e:
        log_with_time(f"Error deleting JSON files: {e}", level="ERROR")
        return JSONResponse(
            content={"status": "error", "message": str(e)},
            status_code=500
        )


@app.post("/api/discussion")
async def get_discussion_gemini(request: DiscussionRequest):
    # Geminiã§ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³
    log_with_time(f"Discussion request (Gemini): {request}", level="DEBUG")
    prompt = (
        "ä»Šã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã“ã®æ¼«ç”»ã«ã¤ã„ã¦ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã—ã¾ã—ã‚‡ã†ã€‚è³ªå•ã¯ã“ã¡ã‚‰ã§ã™ï¼š"
        + request.question
    )
    summary = json.loads(request.summary) if isinstance(request.summary, str) else request.summary
    response = fetch_gemini_discussion_response(prompt, summary, request.imageData)
    
    # Geminiã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†
    response_data = {
        "role": "assistant",
        "content": [{"type": "text", "text": response.text}],
        "model": "gemini-2.5-flash-preview-05-20",
    }
    
    # æ—¢å­˜ã®å†…å®¹ã‚’ãƒªã‚¹ãƒˆã¨ã—ã¦å–å¾—
    existing_data = []
    try:
        with open(
            f"public/saved_json/discussion_{request.dataName}_{request.currentIndex}.json",
            "r",
        ) as f:
            existing_data = json.load(f)
    except FileNotFoundError:
        pass  # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦ä½œæˆ
    
    existing_data.append({"user": request.question})
    existing_data.append(response_data)
    
    # æ›´æ–°ã•ã‚ŒãŸãƒªã‚¹ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€
    with open(
        f"public/saved_json/discussion_{request.dataName}_{request.currentIndex}.json",
        "w",
    ) as f:
        json.dump(existing_data, f, ensure_ascii=False, indent=2)
    
    return JSONResponse(content=response_data)


# å„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§ç”»åƒãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã‚’è¡Œã†é–¢æ•°
def validate_image_data(data: dict) -> dict:
    """ç”»åƒãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã¨æ­£è¦åŒ–"""
    validated_data = {}
    for img_key, img_value in data.items():
        if isinstance(img_value, dict) and "komaPath" in img_value:
            validated_data[img_key] = img_value
        else:
            # é©åˆ‡ãªå½¢å¼ã§ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼å‡¦ç†
            log_with_time(f"Invalid image data format for key {img_key}", level="WARNING")
    return validated_data


@app.post("/api/feedback-claude")
async def get_feedback(request: FeedbackRequest):
    # ã“ã“ã§LLMã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã—ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å–å¾—ã™ã‚‹å‡¦ç†ã‚’å®Ÿè£…
    log_with_time(f"Feedback request (Claude): {request}", level="DEBUG")
    prompt = "ç”»åƒç¾¤ã¨imageDataã‹ã‚‰4ã‚³ãƒå…¨ä½“ã§ã©ã‚“ãªè©±ã‹ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„"
    # import pdb;pdb.set_trace()
    response = fetch_anthropic_4koma_response(
        prompt, list(request.imagePathList.values()), request.imageData
    )
    # print(response.content)
    with open(
        f"public/saved_json/feedback_{request.dataName}_{request.currentIndex}.json",
        "w",
    ) as f:
        f.write(json.dumps(response.json()))
    return JSONResponse(content=response.json())


@app.post("/api/feedback")
async def get_feedback_gemini(request: FeedbackRequest):
    # Geminiã§4ã‚³ãƒå…¨ä½“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å–å¾—
    log_with_time(f"Feedback request (Gemini): {request}", level="DEBUG")
    prompt = "ç”»åƒç¾¤ã¨imageDataã‹ã‚‰4ã‚³ãƒå…¨ä½“ã§ã©ã‚“ãªè©±ã‹ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„"
    response = fetch_gemini_4koma_response(
        prompt, list(request.imagePathList.values()), request.imageData
    )

    try:
        # Geminiã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†
        response_data = {
            "role": "assistant",
            "content": [{"type": "text", "text": response.text}],
            "model": "gemini-2.5-flash-preview-05-20",
        }

        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with open(
            f"public/saved_json/feedback_{request.dataName}_{request.currentIndex}.json",
            "w",
        ) as f:
            f.write(json.dumps(response_data))

        return JSONResponse(content=response_data)

    except Exception as e:
        log_with_time(f"Error processing Gemini feedback: {e}", level="ERROR")
        return JSONResponse(
            content={"error": f"Failed to get feedback with Gemini: {str(e)}"},
            status_code=500,
        )





@app.post("/api/analyze-image-improved/")
async def analyze_image_improved(data: CombinedImageData):
    """æ”¹å–„ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ãŸç”»åƒåˆ†æã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆAIæ¤œå‡ºçµæœæ´»ç”¨ç‰ˆï¼‰"""
    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ãƒ­ã‚°
        log_with_time("ğŸ”„ æ”¹å–„ç‰ˆAPIå‘¼ã³å‡ºã—é–‹å§‹", level="INFO")
        log_with_time(f"ğŸ“¥ å—ä¿¡ãƒ‡ãƒ¼ã‚¿: mode={data.mode}", level="DEBUG")
        log_with_time(f"ğŸ“¥ detectionResultsæœ‰ç„¡: {bool(hasattr(data, 'detectionResults') and data.detectionResults)}", level="DEBUG")
        
        # APIã‚’ä½¿ç”¨
        llm_manager = LLMManager()
        config = llm_manager.config
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        from prompts import IMPROVED_PROMPT_SINGLE, IMPROVED_PROMPT_FOUR_PANEL
        
        # å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ­ã‚°å‡ºåŠ›
        log_with_time(f"å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: é•·ã•={len(data.prompt) if data.prompt else 0}, å†…å®¹={data.prompt[:100] if data.prompt else 'None'}", level="DEBUG")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯
        # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰è©³ç´°ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆAIæ¤œå‡ºçµæœä»˜ãï¼‰ãŒé€ä¿¡ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        has_enhanced_prompt = (
            data.prompt and 
            len(data.prompt) > 1000 and 
            ("AIæ¤œå‡ºçµæœ" in data.prompt or "detected_characters" in data.prompt)
        )
        
        if has_enhanced_prompt:
            # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§ç”Ÿæˆã•ã‚ŒãŸæ‹¡å¼µãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãã®ã¾ã¾ä½¿ç”¨
            log_with_time("âœ… ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”Ÿæˆã®æ‹¡å¼µãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨", level="INFO")
            log_with_time(f"æ‹¡å¼µãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©³ç´°: é•·ã•={len(data.prompt)}, AIæ¤œå‡ºçµæœå«ã‚€={('detected_characters' in data.prompt)}", level="DEBUG")
        else:
            # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®è©³ç´°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒãªã„å ´åˆã®ã¿æ”¹å–„ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨
            log_with_time("âš ï¸ è©³ç´°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãªã— - æ”¹å–„ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯", level="WARNING")
            
            # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦æ”¹å–„ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨
            if data.mode == "combined-four-panel" or data.mode == "four-panel":
                improved_prompt = IMPROVED_PROMPT_FOUR_PANEL
            else:
                improved_prompt = IMPROVED_PROMPT_SINGLE
            
            # æ”¹å–„ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®š
            data.prompt = improved_prompt
            log_with_time(f"æ”¹å–„ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š: é•·ã•={len(data.prompt)}, æœ€åˆã®100æ–‡å­—={data.prompt[:100]}", level="DEBUG")
            
            # AIæ¤œå‡ºçµæœãŒã‚ã‚‹å ´åˆã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ 
            if hasattr(data, 'detectionResults') and data.detectionResults:
                detection_results_str = f"\n\n## AIæ¤œå‡ºçµæœ:\n{json.dumps(data.detectionResults, ensure_ascii=False, indent=2)}"
                data.prompt += detection_results_str
                log_with_time(f"AIæ¤œå‡ºçµæœè¿½åŠ : æ¤œå‡ºçµæœé•·ã•={len(detection_results_str)}, ç·ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ã•={len(data.prompt)}", level="DEBUG")
            else:
                log_with_time("AIæ¤œå‡ºçµæœãªã— - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã¯ãƒ™ãƒ¼ã‚¹ã®ã¿ä½¿ç”¨", level="DEBUG")
        
        # æ”¹å–„ç‰ˆAPIå°‚ç”¨ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆAPIã®ã¿ä½¿ç”¨ï¼‰
        log_with_time("ğŸ”§ æ”¹å–„ç‰ˆAPI - APIä½¿ç”¨", level="DEBUG")
        
        if data.mode == "combined-four-panel" or data.mode == "four-panel":
            if data.komaPath.startswith("data:image"):
                original_path = data.originalImagePath if hasattr(data, 'originalImagePath') else None
                log_with_time("ğŸŒ æ”¹å–„ç‰ˆAPI(4ã‚³ãƒ) - APIå‘¼ã³å‡ºã—", level="INFO")
                response = fetch_gemini_response_base64(data.prompt, data.komaPath, original_image_path=original_path)
            else:
                image_path = "./public" + data.komaPath
                log_with_time("ğŸŒ æ”¹å–„ç‰ˆAPI(4ã‚³ãƒ, ãƒ•ã‚¡ã‚¤ãƒ«) - APIå‘¼ã³å‡ºã—", level="INFO")
                response = fetch_gemini_response(data.prompt, image_path)
        else:
            if data.useMultiModal and data.promptMessages:
                response = fetch_gemini_response_multimodal(data.promptMessages)
            else:
                if data.komaPath.startswith("data:image"):
                    original_path = data.originalImagePath if hasattr(data, 'originalImagePath') else None
                    log_with_time(f"æ”¹å–„ç‰ˆAPI - Gemini APIã«æ¸¡ã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ã•: {len(data.prompt)}", level="DEBUG")
                    log_with_time(f"æ”¹å–„ç‰ˆAPI - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€åˆã®200æ–‡å­—: {data.prompt[:200]}", level="DEBUG")
                    response = fetch_gemini_response_base64(data.prompt, data.komaPath, original_image_path=original_path)
                else:
                    image_path = "./public" + data.komaPath
                    response = fetch_gemini_response(data.prompt, image_path)

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ï¼ˆæ—¢å­˜ã¨åŒã˜ï¼‰
        content = response.text
        
        if "```json" in content:
            json_start = content.find("```json") + 7
            json_end = content.find("```", json_start)
            json_content = content[json_start:json_end].strip()
        else:
            json_content = content

        try:
            content_data = json.loads(json_content)
        except json.JSONDecodeError as e:
            import re
            json_content = re.sub(r"'([^']*)':", r'"\1":', json_content)
            json_content = re.sub(r":\s*'([^']*)'", r': "\1"', json_content)
            json_content = re.sub(r',\s*}', '}', json_content)
            json_content = re.sub(r',\s*]', ']', json_content)
            try:
                content_data = json.loads(json_content)
            except:
                content_data = {"error": "Failed to parse JSON response", "raw_content": content[:1000]}

        # å¹ãå‡ºã—æ¤œå‡ºï¼ˆæ—¢å­˜ã¨åŒã˜ï¼‰
        enable_balloon_detection = getattr(data, 'enableBalloonDetection', True)
        if enable_balloon_detection:
            balloon_detector = get_balloon_detector()
            
            if data.mode == "four-panel":
                for i, panel_key in enumerate(["panel1", "panel2", "panel3", "panel4"], 1):
                    if panel_key in content_data and isinstance(content_data[panel_key], dict):
                        image_key = f"image{i}"
                        if hasattr(data, 'imagePathList') and image_key in data.imagePathList:
                            image_path = "./public" + data.imagePathList[image_key]
                            balloon_detections = balloon_detector.detect_from_path(image_path)
                        else:
                            balloon_detections = []
                        
                        if balloon_detections:
                            content_data[panel_key] = integrate_balloon_detection(
                                content_data[panel_key], 
                                balloon_detections
                            )
            
            elif data.mode == "combined-four-panel":
                if data.komaPath.startswith("data:image"):
                    balloon_detections = balloon_detector.detect_from_base64(data.komaPath)
                else:
                    image_path = "./public" + data.komaPath
                    balloon_detections = balloon_detector.detect_from_path(image_path)
                
                if balloon_detections:
                    panel_balloons = {"panel1": [], "panel2": [], "panel3": [], "panel4": []}
                    
                    for detection in balloon_detections:
                        x_coord = detection["coordinate"][0]
                        y_coord = detection["coordinate"][1]
                        
                        if x_coord >= 0.5 and y_coord < 0.5:
                            panel_balloons["panel1"].append(detection)
                        elif x_coord < 0.5 and y_coord < 0.5:
                            panel_balloons["panel2"].append(detection)
                        elif x_coord >= 0.5 and y_coord >= 0.5:
                            panel_balloons["panel3"].append(detection)
                        else:
                            panel_balloons["panel4"].append(detection)
                    
                    for panel_key, detections in panel_balloons.items():
                        if panel_key in content_data and detections:
                            content_data[panel_key] = integrate_balloon_detection(
                                content_data[panel_key],
                                detections
                            )

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹ç¯‰ï¼ˆAPIä½¿ç”¨ï¼‰
        model_name = "gemini-2.5-flash-preview-05-20"
        ret_data = {
            "model": model_name,
            "content_data": content_data,
            "improved_prompt": True  # æ”¹å–„ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ãŸã“ã¨ã‚’ç¤ºã™ãƒ•ãƒ©ã‚°
        }

        return JSONResponse(content=ret_data)

    except Exception as e:
        log_with_time(f"Error in improved analysis: {e}", level="ERROR")
        return JSONResponse(
            content={"error": f"Failed to analyze image with improved prompt: {str(e)}"},
            status_code=500,
        )


@app.post("/api/analyze-image/")
async def analyze_image_gemini(data: CombinedImageData):
    """Geminiã§ã®ç”»åƒåˆ†æã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆAPIã®ã¿ï¼‰"""
    try:
        # æ¤œå‡ºãƒ»åˆ†é¡ãƒ»å¯è¦–åŒ–ã®ã¿ãƒ¢ãƒ¼ãƒ‰
        if getattr(data, 'detectOnly', False):
            log_with_time("ğŸ¯ æ¤œå‡ºãƒ»åˆ†é¡ãƒ»å¯è¦–åŒ–ã®ã¿ãƒ¢ãƒ¼ãƒ‰é–‹å§‹", level="INFO")
            
            # detectionModeãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‚’åˆ‡ã‚Šæ›¿ãˆ
            detection_mode = getattr(data, 'detectionMode', None)
            if detection_mode:
                try:
                    pipeline = get_yuyu_pipeline()
                    if pipeline:
                        multiclass_mode = detection_mode == "multiclass"
                        pipeline.set_mode(multiclass_mode=multiclass_mode)
                        log_with_time(f"ğŸ”„ æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ: {detection_mode} (multiclass={multiclass_mode})", level="INFO")
                    else:
                        log_with_time("âš ï¸ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒåˆ©ç”¨ã§ããªã„ãŸã‚æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆã‚’ã‚¹ã‚­ãƒƒãƒ—", level="WARNING")
                except Exception as e:
                    log_with_time(f"âŒ æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆã‚¨ãƒ©ãƒ¼: {str(e)}", level="ERROR")
            
            # ç”»åƒãƒ‘ã‚¹ã‚’å–å¾—
            if data.komaPath.startswith("data:image"):
                # Base64ã®å ´åˆã¯ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                import tempfile
                import base64 as b64
                
                header, image_data = data.komaPath.split(",", 1)
                image_bytes = b64.b64decode(image_data)
                
                with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp_file:
                    tmp_file.write(image_bytes)
                    image_path = tmp_file.name
            else:
                image_path = "./public" + data.komaPath
            
            try:
                # ç”»åƒã‚’èª­ã¿è¾¼ã¿
                import cv2
                image = cv2.imread(image_path)
                if image is None or image.size == 0:
                    raise ValueError(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“: {image_path}")
                
                # å¹ãå‡ºã—æ¤œå‡ºã‚’å®Ÿè¡Œ
                balloon_detector = get_balloon_detector()
                balloon_detections = balloon_detector.detect_balloons(
                    image=image,
                    confidence_threshold=0.25,
                    detect_tails=True
                )
                
                # äººç‰©æ¤œå‡ºã‚’å®Ÿè¡Œï¼ˆãƒãƒ«ãƒã‚¯ãƒ©ã‚¹å¯¾å¿œï¼‰
                character_detections = []
                if yolo_dinov2_pipeline is not None:
                    try:
                        # ä¸€æ™‚çš„ãªç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã—ã¦ process_image ã‚’ä½¿ç”¨
                        import tempfile
                        import os
                        
                        temp_image_path = None
                        try:
                            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ç”»åƒã‚’ä¿å­˜
                            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_file:
                                temp_image_path = temp_file.name
                                cv2.imwrite(temp_image_path, image)
                            
                            # çµ±ä¸€ã•ã‚ŒãŸprocess_imageãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼ˆç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦å‡¦ç†ã•ã‚Œã‚‹ï¼‰
                            log_with_time(f"äººç‰©æ¤œå‡ºå®Ÿè¡Œ: ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹={yolo_dinov2_pipeline.multiclass_mode}", level="INFO")
                            processing_result = yolo_dinov2_pipeline.process_image(temp_image_path)
                            
                            # çµæœã‚’å¤‰æ›
                            h, w = image.shape[:2]
                            
                            for i, result in enumerate(processing_result.results):
                                x1, y1, x2, y2 = result.detection.bbox
                                identification = result.identification
                                
                                # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—ï¼ˆæ­£è¦åŒ–ï¼‰
                                center_x = (x1 + x2) / 2 / w
                                center_y = (y1 + y2) / 2 / h
                                
                                character_detections.append({
                                    "characterId": f"char_{i + 1}",
                                    "characterName": identification.character_name,
                                    "confidence": identification.confidence,
                                    "classificationConfidence": identification.confidence,
                                    "detectionConfidence": result.detection.confidence,
                                    "boundingBox": {
                                        "x1": float(x1),
                                        "y1": float(y1),
                                        "x2": float(x2),
                                        "y2": float(y2)
                                    },
                                    "coordinate": [center_x, center_y]
                                })
                        
                        finally:
                            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                            if temp_image_path and os.path.exists(temp_image_path):
                                os.unlink(temp_image_path)
                                
                    except Exception as e:
                        log_with_time(f"äººç‰©æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}", level="WARNING")
                
                # å¯è¦–åŒ–ã‚’å®Ÿè¡Œï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
                visualization_image_base64 = None
                if getattr(data, 'enableVisualization', True):
                    from balloon_detection_integration import draw_tail_shape_results_on_image
                    import base64 as b64
                    
                    # å¯è¦–åŒ–ç”»åƒã‚’ç”Ÿæˆï¼ˆäººç‰©æ¤œå‡ºçµæœã‚‚å«ã‚€ï¼‰
                    visualization_image = draw_tail_shape_results_on_image(
                        image, balloon_detections, character_detections
                    )
                    
                    # Base64ã«å¤‰æ›
                    _, buffer = cv2.imencode('.png', visualization_image)
                    visualization_image_base64 = b64.b64encode(buffer).decode('utf-8')
                
                # æ¤œå‡ºçµæœã‚’æ•´ç†
                detection_results = {
                    "balloon_detections": balloon_detections,
                    "detection_count": len(balloon_detections),
                    "character_detections": character_detections,
                    "character_count": len(character_detections)
                }
                
                # æ¤œå‡ºçµæœã®ã¿ã‚’è¿”ã™
                ret_data = {
                    "model": "detection-only",
                    "detection_results": detection_results,
                    "mode": "detection_only"
                }
                
                # å¯è¦–åŒ–ç”»åƒãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
                if visualization_image_base64:
                    ret_data["visualization_image"] = f"data:image/png;base64,{visualization_image_base64}"
                
                log_with_time("âœ… æ¤œå‡ºãƒ»åˆ†é¡ãƒ»å¯è¦–åŒ–ã®ã¿ãƒ¢ãƒ¼ãƒ‰å®Œäº†", level="INFO")
                return JSONResponse(content=ret_data)
                
            finally:
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                if data.komaPath.startswith("data:image") and 'image_path' in locals():
                    import os
                    try:
                        os.unlink(image_path)
                    except:
                        pass
        
        # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼ˆGemini APIä½¿ç”¨ï¼‰
        llm_manager = LLMManager()
        config = llm_manager.config
        
        log_with_time("ğŸŒ Gemini APIä½¿ç”¨", level="INFO")

        if data.mode == "four-panel":
            # 4ã‚³ãƒå½¢å¼ã®å ´åˆ
            if data.komaPath.startswith("data:image"):
                # Base64å½¢å¼ã®ç”»åƒ
                original_path = data.originalImagePath if hasattr(data, 'originalImagePath') else None
                response = fetch_gemini_response_base64(data.prompt, data.komaPath, original_image_path=original_path)
            else:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å ´åˆ
                image_path = "./public" + data.komaPath
                response = fetch_gemini_response(data.prompt, image_path)
        else:
            # combined-four-panelå½¢å¼ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
            if data.useMultiModal and data.promptMessages:
                # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å½¢å¼
                log_with_time("ğŸ”„ ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å½¢å¼ã§APIå‘¼ã³å‡ºã—", level="INFO")
                response = fetch_gemini_response_multimodal(data.promptMessages)
            else:
                # å¾“æ¥ã®å½¢å¼
                if data.komaPath.startswith("data:image"):
                    # Base64ç”»åƒ
                    original_path = data.originalImagePath if hasattr(data, 'originalImagePath') else None
                    log_with_time("ğŸ–¼ï¸ Base64ç”»åƒã§APIå‘¼ã³å‡ºã—", level="INFO")
                    response = fetch_gemini_response_base64(data.prompt, data.komaPath, original_image_path=original_path)
                else:
                    image_path = "./public" + data.komaPath
                    response = fetch_gemini_response(data.prompt, image_path)

        # Geminiã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ç›´æ¥ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        content = response.text
        log_with_time(f"ğŸ” ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ: {content[:200]}...", level="DEBUG")

        # JSONã‚’æŠ½å‡ºï¼ˆ```json ... ``` ã®å½¢å¼ã‚’æƒ³å®šï¼‰
        if "```json" in content:
            json_start = content.find("```json") + 7
            json_end = content.find("```", json_start)
            json_content = content[json_start:json_end].strip()
        else:
            # JSONãƒ–ãƒ­ãƒƒã‚¯ãŒãªã„å ´åˆã¯å…¨ä½“ã‚’JSONã¨ã—ã¦æ‰±ã†
            json_content = content

        # JSONã‚’ãƒ‘ãƒ¼ã‚¹
        try:
            content_data = json.loads(json_content)
        except json.JSONDecodeError as e:
            log_with_time(f"JSON parse error: {e}", level="ERROR")
            log_with_time(f"Content to parse: {json_content[:500]}...", level="DEBUG")
            # JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã€æ­£è¦è¡¨ç¾ã§ä¿®æ­£ã‚’è©¦ã¿ã‚‹
            import re
            # ã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã‚’ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã«å¤‰æ›
            json_content = re.sub(r"'([^']*)':", r'"\1":', json_content)
            json_content = re.sub(r":\s*'([^']*)'", r': "\1"', json_content)
            # æœ«å°¾ã®ã‚«ãƒ³ãƒã‚’å‰Šé™¤
            json_content = re.sub(r',\s*}', '}', json_content)
            json_content = re.sub(r',\s*]', ']', json_content)
            try:
                content_data = json.loads(json_content)
            except:
                # ãã‚Œã§ã‚‚ãƒ‘ãƒ¼ã‚¹ã§ããªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
                content_data = {"error": "Failed to parse JSON response", "raw_content": content[:1000]}

        # 4ã‚³ãƒå½¢å¼ã®å ´åˆã¯å„ãƒ‘ãƒãƒ«ã‹ã‚‰ä¸è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å‰Šé™¤
        if isinstance(content_data, dict):
            if "panel1" in content_data:
                # 4ã‚³ãƒå½¢å¼ã®å ´åˆ
                for panel_key in ["panel1", "panel2", "panel3", "panel4"]:
                    if panel_key in content_data and isinstance(content_data[panel_key], dict):
                        content_data[panel_key].pop("charactersNum", None)
                        content_data[panel_key].pop("serifsNum", None)
            else:
                # å˜ä¸€ãƒ‘ãƒãƒ«å½¢å¼ã®å ´åˆ
                content_data.pop("charactersNum", None)
                content_data.pop("serifsNum", None)

        log_with_time(f"Processed content_data (Gemini): {content_data}", level="DEBUG")
        
        # å¹ãå‡ºã—æ¤œå‡ºã‚’å®Ÿè¡Œï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        enable_balloon_detection = getattr(data, 'enableBalloonDetection', True)
        if enable_balloon_detection:
            log_with_time("ğŸˆ å¹ãå‡ºã—æ¤œå‡ºã‚’é–‹å§‹ã—ã¾ã™", level="INFO")
            balloon_detector = get_balloon_detector()
            
            if data.mode == "four-panel":
                # 4ã‚³ãƒå½¢å¼ã®å ´åˆã€å„ãƒ‘ãƒãƒ«ã§å¹ãå‡ºã—æ¤œå‡º
                for i, panel_key in enumerate(["panel1", "panel2", "panel3", "panel4"], 1):
                    if panel_key in content_data and isinstance(content_data[panel_key], dict):
                        # å¯¾å¿œã™ã‚‹ç”»åƒã‚’å–å¾—
                        image_key = f"image{i}"
                        if hasattr(data, 'imagePathList') and image_key in data.imagePathList:
                            image_path = "./public" + data.imagePathList[image_key]
                            balloon_detections = balloon_detector.detect_from_path(image_path)
                        elif data.komaPath.startswith("data:image"):
                            # Base64ç”»åƒã®å ´åˆï¼ˆçµåˆç”»åƒãªã®ã§å€‹åˆ¥ãƒ‘ãƒãƒ«ã®æ¤œå‡ºã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
                            balloon_detections = []
                        else:
                            balloon_detections = []
                        
                        # å¹ãå‡ºã—æ¤œå‡ºçµæœã‚’çµ±åˆ
                        if balloon_detections:
                            content_data[panel_key] = integrate_balloon_detection(
                                content_data[panel_key], 
                                balloon_detections
                            )
                            log_with_time(f"âœ… {panel_key}: {len(balloon_detections)}å€‹ã®å¹ãå‡ºã—ã‚’æ¤œå‡º", level="INFO")
            
            elif data.mode == "combined-four-panel":
                # çµåˆ4ã‚³ãƒå½¢å¼ã®å ´åˆ
                if data.komaPath.startswith("data:image"):
                    # Base64ç”»åƒå…¨ä½“ã§å¹ãå‡ºã—æ¤œå‡º
                    balloon_detections = balloon_detector.detect_from_base64(data.komaPath)
                else:
                    image_path = "./public" + data.komaPath
                    balloon_detections = balloon_detector.detect_from_path(image_path)
                
                if balloon_detections:
                    # å„ãƒ‘ãƒãƒ«ã«å¹ãå‡ºã—ã‚’å‰²ã‚Šå½“ã¦ï¼ˆåº§æ¨™ãƒ™ãƒ¼ã‚¹ï¼‰
                    panel_balloons = {"panel1": [], "panel2": [], "panel3": [], "panel4": []}
                    
                    for detection in balloon_detections:
                        # åº§æ¨™ã‹ã‚‰æ‰€å±ãƒ‘ãƒãƒ«ã‚’åˆ¤å®šï¼ˆ2x2ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’æƒ³å®šï¼‰
                        x_coord = detection["coordinate"][0]
                        y_coord = detection["coordinate"][1]
                        
                        if x_coord >= 0.5 and y_coord < 0.5:
                            panel_balloons["panel1"].append(detection)
                        elif x_coord < 0.5 and y_coord < 0.5:
                            panel_balloons["panel2"].append(detection)
                        elif x_coord >= 0.5 and y_coord >= 0.5:
                            panel_balloons["panel3"].append(detection)
                        else:
                            panel_balloons["panel4"].append(detection)
                    
                    # å„ãƒ‘ãƒãƒ«ã«å¹ãå‡ºã—æƒ…å ±ã‚’çµ±åˆ
                    for panel_key, detections in panel_balloons.items():
                        if panel_key in content_data and detections:
                            content_data[panel_key] = integrate_balloon_detection(
                                content_data[panel_key],
                                detections
                            )
                            log_with_time(f"âœ… {panel_key}: {len(detections)}å€‹ã®å¹ãå‡ºã—ã‚’æ¤œå‡º", level="INFO")

        # ç”»åƒå¯è¦–åŒ–å‡¦ç†ï¼ˆæœ‰åŠ¹ãªå ´åˆã®ã¿ï¼‰
        visualization_image_base64 = None
        if getattr(data, 'enableVisualization', False) and data.enableBalloonDetection:
            try:
                import cv2
                import base64
                import io
                from PIL import Image
                import numpy as np
                
                # å…ƒç”»åƒã‚’èª­ã¿è¾¼ã¿
                if data.komaPath.startswith("data:image"):
                    # Base64ç”»åƒã®å ´åˆ
                    header, encoded = data.komaPath.split(",", 1)
                    image_data = base64.b64decode(encoded)
                    pil_image = Image.open(io.BytesIO(image_data))
                    image_np = np.array(pil_image)
                    if len(image_np.shape) == 3 and image_np.shape[2] == 4:  # RGBA -> RGB
                        image_np = cv2.cvtColor(image_np, cv2.COLOR_RGBA2RGB)
                else:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å ´åˆ
                    image_path = "./public" + data.komaPath
                    image_np = cv2.imread(image_path)
                    if image_np is not None:
                        image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)
                
                # å¹ãå‡ºã—æ¤œå‡ºçµæœãŒã‚ã‚Œã°å¯è¦–åŒ–
                if image_np is not None and 'balloon_detections' in locals() and balloon_detections:
                    # å°»å°¾å½¢çŠ¶åˆ†é¡çµæœã‚’ç”»åƒä¸Šã«æç”»
                    visualized_image = draw_tail_shape_results_on_image(image_np, balloon_detections)
                    
                    # PILã«å¤‰æ›ã—ã¦Base64ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                    pil_result = Image.fromarray(visualized_image)
                    buffer = io.BytesIO()
                    pil_result.save(buffer, format='PNG')
                    buffer.seek(0)
                    visualization_image_base64 = base64.b64encode(buffer.getvalue()).decode()
                    
                    log_with_time(f"âœ… ç”»åƒå¯è¦–åŒ–å®Œäº†: {len(balloon_detections)}å€‹ã®æ¤œå‡ºçµæœã‚’æç”»", level="INFO")
                
            except Exception as e:
                log_with_time(f"âŒ ç”»åƒå¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}", level="ERROR")
                import traceback
                traceback.print_exc()

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ï¼ˆAPIä½¿ç”¨ï¼‰
        model_name = "gemini-2.5-flash-preview-05-20"
        ret_data = {
            "model": model_name,
            "content_data": content_data,
        }
        
        # å¯è¦–åŒ–ç”»åƒãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if visualization_image_base64:
            ret_data["visualization_image"] = f"data:image/png;base64,{visualization_image_base64}"

        return JSONResponse(content=ret_data)

    except Exception as e:
        log_with_time(f"Error processing Gemini response: {e}", level="ERROR")
        return JSONResponse(
            content={"error": f"Failed to analyze image with Gemini: {str(e)}"},
            status_code=500,
        )




@app.get("/api/load-json")
async def load_json(dataName: str, currentIndex: int):
    """ä¿å­˜æ¸ˆã¿ã®ãƒ•ã‚©ãƒ¼ãƒ JSONãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    try:
        json_path = f"public/saved_json/imageData_{dataName}_{currentIndex}.json"
        log_with_time(f"Load JSON request: {json_path}", level="DEBUG")
        
        if not os.path.exists(json_path):
            log_with_time(f"JSON file not found: {json_path}", level="INFO")
            return JSONResponse(content=None, status_code=200)
        
        with open(json_path, "r", encoding="utf-8") as f:
            image_data = json.load(f)
        
        log_with_time(f"JSON loaded successfully: {json_path}", level="INFO")
        return JSONResponse(content=image_data)
    except Exception as e:
        log_with_time(f"âŒ JSONèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}", level="ERROR")
        return JSONResponse(
            content={"error": str(e)},
            status_code=500
        )


@app.post("/api/save-json")
async def save_json(data: ImageData):
    log_with_time(f"Save JSON request: {data}", level="DEBUG")
    json_path = f"public/saved_json/imageData_{data.dataName}_{data.currentIndex}.json"
    with open(json_path, "w") as f:
        f.write(json.dumps(data.imageData))
    return {"result": "saved!"}


@app.post("/api/save-csv")
async def save_csv(request: Request):
    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚’å–å¾—
        raw_data = await request.json()
        log_with_time(f"ğŸ“¥ Save CSV ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡: {raw_data}", level="DEBUG")
        
        # Pydanticãƒ¢ãƒ‡ãƒ«ã§ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        data = ImageData(**raw_data)
        log_with_time(f"âœ… ImageDataãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æˆåŠŸ: {data.dataName}", level="DEBUG")
    except Exception as e:
        log_with_time(f"âŒ Save CSV ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}", level="ERROR")
        log_with_time(f"âŒ ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {raw_data if 'raw_data' in locals() else 'ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—'}", level="ERROR")
        raise HTTPException(status_code=422, detail=f"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    log_with_time(f"Save CSV request: {data}", level="DEBUG")
    
    # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰é€ä¿¡ã•ã‚ŒãŸdataNameã‚’ç›´æ¥ä½¿ç”¨
    data_name = data.dataName
    
    # JSONå½¢å¼ã§ä¿å­˜ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æœ›ã«å¾“ã„ï¼‰
    json_data = {
        "dataName": data_name,
        "currentIndex": data.currentIndex,
        "komaPath": data.komaPath,
        "imageData": data.imageData.dict() if hasattr(data.imageData, 'dict') else dict(data.imageData),
        "summary": data.summary,
        "timestamp": datetime.now().isoformat()
    }
    
    json_filename = f"imageData_{data_name}_{data.currentIndex}.json"
    json_path = f"public/saved_json/{json_filename}"
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    os.makedirs("public/saved_json", exist_ok=True)
    
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(json_data, f, ensure_ascii=False, indent=2)
    
    log_with_time(f"âœ… JSONä¿å­˜å®Œäº†: {json_path}")
    return {"message": f"Data saved successfully as JSON: {json_filename}"}
    # except Exception as e:
    # raise HTTPException(status_code=500, detail=str(e))


# ================== Human in the Loop æ©Ÿèƒ½ ==================

def calculate_confidence_scores(data: dict, model: str = "gemini") -> Dict[str, float]:
    """AIã®ææ¡ˆã«å¯¾ã™ã‚‹ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
    confidence_scores = {}
    
    # ãƒ¢ãƒ‡ãƒ«åˆ¥ã®åŸºæœ¬ä¿¡é ¼åº¦
    base_confidence = {
        "gemini": 0.85,
        "gpt-4": 0.88,
        "claude": 0.86
    }.get(model, 0.80)
    
    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼èªè­˜ã®ä¿¡é ¼åº¦
    for i, char in enumerate(data.get("characters", [])):
        char_key = f"characters.{i}"
        
        # åå‰ã®ä¿¡é ¼åº¦ï¼ˆæ—¢çŸ¥ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‹ã©ã†ã‹ï¼‰
        known_characters = ["ç¸", "å”¯", "ç›¸å·", "ãµã¿", "ã¿ã»", "åƒç©‚", "å²¡é‡", "ä½³"]
        if char.get("character") in known_characters:
            confidence_scores[f"{char_key}.character"] = base_confidence * 1.1
        else:
            confidence_scores[f"{char_key}.character"] = base_confidence * 0.7
        
        # ã‚»ãƒªãƒ•ã®ä¿¡é ¼åº¦ï¼ˆé•·ã•ãƒ™ãƒ¼ã‚¹ï¼‰
        serif_length = len(char.get("serif", ""))
        if serif_length > 0:
            confidence_scores[f"{char_key}.serif"] = min(base_confidence * (1 + serif_length / 50), 0.95)
        
        # è¡¨æƒ…ã®ä¿¡é ¼åº¦
        confidence_scores[f"{char_key}.expression"] = base_confidence * 0.9
        
        # ä½ç½®ã®ä¿¡é ¼åº¦
        confidence_scores[f"{char_key}.position"] = base_confidence * 0.95
    
    # ã‚·ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ä¿¡é ¼åº¦
    if "sceneData" in data:
        confidence_scores["sceneData.scene"] = base_confidence * 0.9
        confidence_scores["sceneData.location"] = base_confidence * 0.85
        confidence_scores["sceneData.backgroundEffects"] = base_confidence * 0.8
    
    return confidence_scores


def calculate_field_similarity(old_value: Any, new_value: Any) -> float:
    """2ã¤ã®å€¤ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
    if old_value == new_value:
        return 1.0
    
    if isinstance(old_value, str) and isinstance(new_value, str):
        # æ–‡å­—åˆ—ã®é¡ä¼¼åº¦
        return SequenceMatcher(None, old_value, new_value).ratio()
    
    if isinstance(old_value, (int, float)) and isinstance(new_value, (int, float)):
        # æ•°å€¤ã®é¡ä¼¼åº¦
        if old_value == 0 and new_value == 0:
            return 1.0
        max_val = max(abs(old_value), abs(new_value))
        if max_val == 0:
            return 1.0
        return 1.0 - abs(old_value - new_value) / max_val
    
    return 0.0


def extract_differences(old_data: dict, new_data: dict, path: str = "") -> List[DiffAnalysis]:
    """2ã¤ã®ãƒ‡ãƒ¼ã‚¿ã®å·®åˆ†ã‚’æŠ½å‡º"""
    differences = []
    
    # old_dataã®ã‚­ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
    for key in old_data:
        current_path = f"{path}.{key}" if path else key
        
        if key not in new_data:
            # å‰Šé™¤ã•ã‚ŒãŸé …ç›®
            differences.append(DiffAnalysis(
                field_path=current_path,
                old_value=old_data[key],
                new_value=None,
                change_type="deleted",
                similarity=0.0
            ))
        elif isinstance(old_data[key], dict) and isinstance(new_data[key], dict):
            # å†å¸°çš„ã«å·®åˆ†ã‚’æŠ½å‡º
            differences.extend(extract_differences(old_data[key], new_data[key], current_path))
        elif isinstance(old_data[key], list) and isinstance(new_data[key], list):
            # ãƒªã‚¹ãƒˆã®å·®åˆ†
            for i, (old_item, new_item) in enumerate(zip(old_data[key], new_data[key])):
                if isinstance(old_item, dict) and isinstance(new_item, dict):
                    differences.extend(extract_differences(old_item, new_item, f"{current_path}.{i}"))
                elif old_item != new_item:
                    differences.append(DiffAnalysis(
                        field_path=f"{current_path}.{i}",
                        old_value=old_item,
                        new_value=new_item,
                        change_type="modified",
                        similarity=calculate_field_similarity(old_item, new_item)
                    ))
            
            # ãƒªã‚¹ãƒˆã®é•·ã•ãŒç•°ãªã‚‹å ´åˆ
            if len(old_data[key]) < len(new_data[key]):
                for i in range(len(old_data[key]), len(new_data[key])):
                    differences.append(DiffAnalysis(
                        field_path=f"{current_path}.{i}",
                        old_value=None,
                        new_value=new_data[key][i],
                        change_type="added",
                        similarity=0.0
                    ))
            elif len(old_data[key]) > len(new_data[key]):
                for i in range(len(new_data[key]), len(old_data[key])):
                    differences.append(DiffAnalysis(
                        field_path=f"{current_path}.{i}",
                        old_value=old_data[key][i],
                        new_value=None,
                        change_type="deleted",
                        similarity=0.0
                    ))
        elif old_data[key] != new_data[key]:
            # å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸ
            differences.append(DiffAnalysis(
                field_path=current_path,
                old_value=old_data[key],
                new_value=new_data[key],
                change_type="modified",
                similarity=calculate_field_similarity(old_data[key], new_data[key])
            ))
    
    # new_dataã®æ–°ã—ã„ã‚­ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
    for key in new_data:
        if key not in old_data:
            current_path = f"{path}.{key}" if path else key
            differences.append(DiffAnalysis(
                field_path=current_path,
                old_value=None,
                new_value=new_data[key],
                change_type="added",
                similarity=0.0
            ))
    
    return differences


def get_history_file_path(image_path: str) -> str:
    """ç”»åƒãƒ‘ã‚¹ã‹ã‚‰å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ"""
    # ç”»åƒåã‚’å–å¾—ã—ã¦åˆ†ã‹ã‚Šã‚„ã™ã„ãƒ•ã‚¡ã‚¤ãƒ«åã«ã™ã‚‹
    # ä¾‹: yuyu10/pages_corrected/combined_koma/four_panel_062.jpg -> four_panel_062_history.json
    image_name = os.path.basename(image_path).replace('.jpg', '').replace('.png', '')
    
    # ç”»åƒåã ã‘ã§ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½œæˆï¼ˆæœ€ã‚‚ã‚ã‹ã‚Šã‚„ã™ã„ï¼‰
    # ãƒ•ã‚¡ã‚¤ãƒ«åã®é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ã€ãƒ‘ã‚¹ã«å«ã¾ã‚Œã‚‹ç‰¹å¾´çš„ãªéƒ¨åˆ†ã‚’è¿½åŠ 
    path_parts = image_path.split('/')
    
    # yuyu10ãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã‚’å«ã‚ã‚‹å ´åˆ
    dataset_name = ""
    if len(path_parts) > 0 and path_parts[0]:
        dataset_name = path_parts[0]
    
    # åŸºæœ¬å½¢å¼: {ç”»åƒå}_history.json
    # é‡è¤‡ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹å ´åˆã®ã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã‚’è¿½åŠ 
    base_name = f"{image_name}_history.json"
    
    # ã‚ˆã‚Šè¤‡é›‘ãªã‚±ãƒ¼ã‚¹ã§ã¯ã€çŸ­ã„ãƒãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨
    if len(image_path) > 80:  # 80æ–‡å­—ä»¥ä¸Šã®å ´åˆã®ã¿ãƒãƒƒã‚·ãƒ¥ä½¿ç”¨
        path_hash = hashlib.md5(image_path.encode()).hexdigest()[:6]
        return f"public/revision_history/{image_name}_{path_hash}_history.json"
    
    return f"public/revision_history/{base_name}"


def get_ai_proposal_file_path(image_path: str, timestamp: str) -> str:
    """AIææ¡ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ"""
    # ç”»åƒåã‚’å–å¾—ã—ã¦åˆ†ã‹ã‚Šã‚„ã™ã„ãƒ•ã‚¡ã‚¤ãƒ«åã«ã™ã‚‹
    image_name = os.path.basename(image_path).replace('.jpg', '').replace('.png', '')
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã«é©ã—ãŸå½¢å¼ã«å¤‰æ›ï¼ˆæ—¥æ™‚ã®ã¿ï¼‰
    timestamp_clean = timestamp.replace(':', '-').replace('.', '-')[:19]
    
    # AIææ¡ˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ã€ç”»åƒå + ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ååˆ†è­˜åˆ¥å¯èƒ½
    return f"public/ai_proposals/{image_name}_{timestamp_clean}.json"


@app.post("/api/save-detection-debug")
async def save_detection_debug(data: dict):
    """AIæ¤œå‡ºãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ä¿å­˜"""
    try:
        debug_dir = data.get("debugDir", "tmp/ai_detection_debug/unknown")
        step = data.get("step", "unknown")
        timestamp = data.get("timestamp", datetime.now().isoformat())
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(debug_dir, exist_ok=True)
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        debug_file = f"{debug_dir}/{step}.json"
        with open(debug_file, "w", encoding="utf-8") as f:
            json.dump({
                "timestamp": timestamp,
                "step": step,
                "imagePathList": data.get("imagePathList", {}),
                "detectionResults": data.get("detectionResults", []),
                "enhancedPrompt": data.get("enhancedPrompt", ""),
                "promptLength": data.get("promptLength", 0),
                "metadata": {
                    "saved_at": datetime.now().isoformat(),
                    "step_description": {
                        "1_detection_results": "AIæ¤œå‡ºçµæœï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ»å¹ãå‡ºã—ï¼‰",
                        "2_enhanced_prompt": "æ‹¡å¼µãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆåŸºæœ¬ç‰ˆï¼‰",
                        "3_improved_prompt": "æ”¹è‰¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆè©³ç´°ç‰ˆï¼‰"
                    }.get(step, "ä¸æ˜ãªã‚¹ãƒ†ãƒƒãƒ—")
                }
            }, f, ensure_ascii=False, indent=2)
        
        log_with_time(f"ğŸ’¾ AIæ¤œå‡ºãƒ‡ãƒãƒƒã‚°æƒ…å ±ä¿å­˜: {debug_file}", level="INFO")
        
        return JSONResponse(content={
            "status": "success",
            "debugFile": debug_file,
            "step": step
        })
        
    except Exception as e:
        log_with_time(f"âŒ AIæ¤œå‡ºãƒ‡ãƒãƒƒã‚°æƒ…å ±ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}", level="ERROR")
        return JSONResponse(
            content={"status": "error", "message": str(e)},
            status_code=500
        )

@app.post("/api/save-ai-proposal")
async def save_ai_proposal(data: Dict[str, Any]):
    """AIææ¡ˆã‚’ä¿å­˜"""
    try:
        timestamp = datetime.now().isoformat()
        image_path = data.get("imagePath")
        model = data.get("model", "gemini")
        proposal_data = data.get("proposalData", {})
        processing_time = data.get("processingTime")
        api_cost = data.get("apiCost")
        
        # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        confidence_scores = calculate_confidence_scores(proposal_data, model)
        
        # AIææ¡ˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        ai_proposal = AIProposal(
            image_path=image_path,
            timestamp=timestamp,
            model=model,
            proposal=proposal_data,
            confidence_scores=confidence_scores,
            processing_time=processing_time,
            api_cost=api_cost
        )
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        Path("public/ai_proposals").mkdir(parents=True, exist_ok=True)
        Path("public/revision_history").mkdir(parents=True, exist_ok=True)
        
        # AIææ¡ˆã‚’å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        proposal_path = get_ai_proposal_file_path(image_path, timestamp)
        with open(proposal_path, "w", encoding="utf-8") as f:
            json.dump(ai_proposal.dict(), f, ensure_ascii=False, indent=2)
        
        # å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã¾ãŸã¯ä½œæˆ
        history_path = get_history_file_path(image_path)
        
        if os.path.exists(history_path):
            # æ—¢å­˜ã®å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€
            with open(history_path, "r", encoding="utf-8") as f:
                history_data = json.load(f)
            history = RevisionHistory(**history_data)
        else:
            # æ–°ã—ã„å±¥æ­´ã‚’ä½œæˆ
            history = RevisionHistory(
                image_path=image_path,
                created_at=timestamp,
                last_updated=timestamp,
                total_revisions=0,
                ai_proposals=[],
                revisions=[],
                current_data=proposal_data
            )
        
        # AIææ¡ˆã‚’å±¥æ­´ã«è¿½åŠ 
        history.ai_proposals.append(ai_proposal)
        
        # AIææ¡ˆã‚’ä¿®æ­£å±¥æ­´ã«ã‚‚è¿½åŠ 
        revision_entry = RevisionEntry(
            timestamp=timestamp,
            revision_type="ai_proposal",
            changes=[],  # åˆå›ãªã®ã§å·®åˆ†ãªã—
            editor="ai",
            confidence=sum(confidence_scores.values()) / len(confidence_scores) if confidence_scores else 0,
            notes=f"Initial AI proposal using {model}"
        )
        history.revisions.append(revision_entry)
        history.total_revisions += 1
        history.last_updated = timestamp
        history.current_data = proposal_data
        
        # å±¥æ­´ã‚’ä¿å­˜
        with open(history_path, "w", encoding="utf-8") as f:
            json.dump(history.dict(), f, ensure_ascii=False, indent=2)
        
        return JSONResponse(content={
            "status": "success",
            "proposalId": f"{image_path}_{timestamp}",
            "confidenceScores": confidence_scores,
            "historyPath": history_path
        })
        
    except Exception as e:
        log_with_time(f"Error saving AI proposal: {e}", level="ERROR")
        return JSONResponse(
            content={"error": f"Failed to save AI proposal: {str(e)}"},
            status_code=500
        )


@app.post("/api/save-human-revision")
async def save_human_revision(data: Dict[str, Any]):
    """äººé–“ã«ã‚ˆã‚‹ä¿®æ­£ã‚’ä¿å­˜ã—ã€å·®åˆ†ã‚’è¨˜éŒ²"""
    try:
        timestamp = datetime.now().isoformat()
        image_path = data.get("imagePath")
        # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã¯revisionDataã§é€ã‚‰ã‚Œã¦ãã‚‹å ´åˆã‚‚ã‚ã‚‹
        new_data = data.get("imageData") or data.get("revisionData", {})
        notes = data.get("notes", "")
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        Path("public/revision_history").mkdir(parents=True, exist_ok=True)
        
        history_path = get_history_file_path(image_path)
        
        if not os.path.exists(history_path):
            # å±¥æ­´ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦ä½œæˆ
            log_with_time(f"Creating new history for {image_path}", level="INFO")
            history = RevisionHistory(
                image_path=image_path,
                created_at=timestamp,
                last_updated=timestamp,
                total_revisions=0,
                ai_proposals=[],
                revisions=[],
                current_data={}  # ç©ºã®çŠ¶æ…‹ã‹ã‚‰é–‹å§‹
            )
        else:
            # æ—¢å­˜ã®å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€
            with open(history_path, "r", encoding="utf-8") as f:
                history_data = json.load(f)
            history = RevisionHistory(**history_data)
        
        # å·®åˆ†ã‚’è¨ˆç®—
        old_data = history.current_data
        differences = extract_differences(old_data, new_data)
        
        # å·®åˆ†ã‚’Dictã«å¤‰æ›
        changes = [diff.dict() for diff in differences]
        
        # ä¿®æ­£ã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆ
        revision_entry = RevisionEntry(
            timestamp=timestamp,
            revision_type="human_edit",
            changes=changes,
            editor="human",
            notes=notes
        )
        
        # å±¥æ­´ã‚’æ›´æ–°
        history.revisions.append(revision_entry)
        history.total_revisions += 1
        history.last_updated = timestamp
        history.current_data = new_data
        
        # å±¥æ­´ã‚’ä¿å­˜
        with open(history_path, "w", encoding="utf-8") as f:
            json.dump(history.dict(), f, ensure_ascii=False, indent=2)
        
        # æ—¢å­˜ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚‚æ›´æ–°ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
        json_path = f"public/saved_json/imageData_{data.get('dataName')}_{data.get('currentIndex')}.json"
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(new_data, f, ensure_ascii=False, indent=2)
        
        return JSONResponse(content={
            "status": "success",
            "revisionId": f"{image_path}_{timestamp}",
            "changesCount": len(changes),
            "changes": changes[:10]  # æœ€åˆã®10ä»¶ã®å¤‰æ›´ã‚’è¿”ã™
        })
        
    except Exception as e:
        log_with_time(f"Error saving human revision: {e}", level="ERROR")
        return JSONResponse(
            content={"error": f"Failed to save human revision: {str(e)}"},
            status_code=500
        )


@app.get("/api/get-revision-history/{image_path:path}")
async def get_revision_history(image_path: str):
    """ç‰¹å®šã®ç”»åƒã®ä¿®æ­£å±¥æ­´ã‚’å–å¾—"""
    try:
        history_path = get_history_file_path(image_path)
        
        if not os.path.exists(history_path):
            return JSONResponse(content={"revisions": [], "aiProposals": []})
        
        with open(history_path, "r", encoding="utf-8") as f:
            history_data = json.load(f)
        
        return JSONResponse(content=history_data)
        
    except Exception as e:
        log_with_time(f"Error getting revision history: {e}", level="ERROR")
        return JSONResponse(
            content={"error": f"Failed to get revision history: {str(e)}"},
            status_code=500
        )


@app.post("/api/export-learning-data")
async def export_learning_data(data: Dict[str, Any]):
    """äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    try:
        export_type = data.get("exportType", "all")  # "all", "corrections_only", "high_confidence"
        min_revisions = data.get("minRevisions", 2)  # æœ€å°ä¿®æ­£å›æ•°
        
        learning_data = []
        history_dir = Path("public/revision_history")
        
        if not history_dir.exists():
            return JSONResponse(content={"error": "No revision history found"}, status_code=404)
        
        # ã™ã¹ã¦ã®å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
        for history_file in history_dir.glob("*_history.json"):
            with open(history_file, "r", encoding="utf-8") as f:
                history = RevisionHistory(**json.load(f))
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶
            if history.total_revisions < min_revisions:
                continue
            
            # AIææ¡ˆã¨äººé–“ã®æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã®å·®åˆ†ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æŠ½å‡º
            if history.ai_proposals and history.revisions:
                for ai_proposal in history.ai_proposals:
                    # äººé–“ã«ã‚ˆã‚‹ä¿®æ­£ã‚’æ¢ã™
                    human_edits = [r for r in history.revisions if r.editor == "human" and r.timestamp > ai_proposal.timestamp]
                    
                    if human_edits:
                        learning_entry = {
                            "image_path": history.image_path,
                            "ai_proposal": ai_proposal.proposal,
                            "human_correction": history.current_data,
                            "confidence_scores": ai_proposal.confidence_scores,
                            "total_edits": len(human_edits),
                            "significant_changes": []
                        }
                        
                        # é‡è¦ãªå¤‰æ›´ã‚’æŠ½å‡º
                        for edit in human_edits:
                            significant = [c for c in edit.changes if c.get("similarity", 1.0) < 0.5]
                            learning_entry["significant_changes"].extend(significant)
                        
                        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                        if export_type == "corrections_only" and not learning_entry["significant_changes"]:
                            continue
                        
                        if export_type == "high_confidence":
                            avg_confidence = sum(ai_proposal.confidence_scores.values()) / len(ai_proposal.confidence_scores)
                            if avg_confidence < 0.8:
                                continue
                        
                        learning_data.append(learning_entry)
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        export_path = f"public/learning_data/export_{timestamp}.json"
        Path("public/learning_data").mkdir(parents=True, exist_ok=True)
        
        with open(export_path, "w", encoding="utf-8") as f:
            json.dump({
                "export_info": {
                    "timestamp": timestamp,
                    "export_type": export_type,
                    "min_revisions": min_revisions,
                    "total_entries": len(learning_data)
                },
                "data": learning_data
            }, f, ensure_ascii=False, indent=2)
        
        # CSVã§ã‚‚ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
        csv_path = f"public/learning_data/export_{timestamp}.csv"
        csv_rows = []
        
        for entry in learning_data:
            for change in entry.get("significant_changes", []):
                csv_rows.append({
                    "image_path": entry["image_path"],
                    "field": change.get("field_path"),
                    "ai_value": change.get("old_value"),
                    "human_value": change.get("new_value"),
                    "change_type": change.get("change_type"),
                    "similarity": change.get("similarity")
                })
        
        if csv_rows:
            df = pd.DataFrame(csv_rows)
            df.to_csv(csv_path, index=False, encoding="utf-8")
        
        return JSONResponse(content={
            "status": "success",
            "exportPath": export_path,
            "csvPath": csv_path if csv_rows else None,
            "totalEntries": len(learning_data),
            "summary": {
                "totalImages": len(set(e["image_path"] for e in learning_data)),
                "totalChanges": sum(len(e["significant_changes"]) for e in learning_data)
            }
        })
        
    except Exception as e:
        log_with_time(f"Error exporting learning data: {e}", level="ERROR")
        return JSONResponse(
            content={"error": f"Failed to export learning data: {str(e)}"},
            status_code=500
        )


# ================== YOLO+DINOv2 æ¤œå‡ºã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ==================

@app.post("/api/detect-characters-yolo-dinov2")
async def detect_characters_yolo_dinov2(request: YoloDinov2DetectionRequest):
    """YOLO+DINOv2ã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ¤œå‡ºãƒ»è­˜åˆ¥ã‚’å®Ÿè¡Œ"""
    try:
        if yolo_dinov2_pipeline is None:
            return JSONResponse(
                content={"error": "YOLO+DINOv2ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"},
                status_code=503
            )
        
        # detectionModeãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‚’åˆ‡ã‚Šæ›¿ãˆ
        if request.detectionMode:
            try:
                multiclass_mode = request.detectionMode == "multiclass"
                yolo_dinov2_pipeline.set_mode(multiclass_mode=multiclass_mode)
                log_with_time(f"ğŸ”„ æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ: {request.detectionMode} (multiclass={multiclass_mode})", level="INFO")
            except Exception as e:
                log_with_time(f"âŒ æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆã‚¨ãƒ©ãƒ¼: {str(e)}", level="ERROR")
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã®ãƒãƒƒãƒ”ãƒ³ã‚°
        CHARACTER_NAME_MAP = {
            "yuzuko": "é‡ã€…åŸã‚†ãšã“",
            "yukari": "æ—¥å‘ç¸",
            "yui": "æ«Ÿäº•å”¯",
            "yoriko": "æ¾æœ¬é ¼å­",
            "chiho": "ç›¸å·åƒç©‚",
            "kei": "å²¡é‡ä½³",
            "fumi": "é•·è°·å·ãµã¿",
            "unknown": "ä¸æ˜"
        }
        
        # ç”»åƒã®æº–å‚™
        if request.komaPath.startswith("data:image"):
            # Base64ãƒ‡ãƒ¼ã‚¿ã®å ´åˆ
            import base64
            import io
            from PIL import Image
            import numpy as np
            
            # Base64ãƒ‡ã‚³ãƒ¼ãƒ‰
            image_data = request.komaPath.split(',')[1]
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes))
            # OpenCVå½¢å¼ã«å¤‰æ›
            image_cv = np.array(image.convert('RGB'))[:, :, ::-1].copy()
        else:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å ´åˆ
            import cv2
            image_path = "./public/" + request.komaPath
            image_cv = cv2.imread(image_path)
            if image_cv is None:
                return JSONResponse(
                    content={"error": f"ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {image_path}"},
                    status_code=400
                )
        
        # ä¸€æ™‚çš„ãªç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã—ã¦å‡¦ç†
        import tempfile
        import os
        
        temp_image_path = None
        try:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ç”»åƒã‚’ä¿å­˜
            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_file:
                temp_image_path = temp_file.name
                cv2.imwrite(temp_image_path, image_cv)
            
            # é–¾å€¤ã®ä¸€æ™‚çš„ãªå¤‰æ›´
            original_detection_threshold = yolo_dinov2_pipeline.detection_conf_threshold
            original_classification_threshold = yolo_dinov2_pipeline.classification_conf_threshold
            
            yolo_dinov2_pipeline.detection_conf_threshold = request.detectionThreshold
            yolo_dinov2_pipeline.classification_conf_threshold = request.classificationThreshold
            
            # çµ±ä¸€ã•ã‚ŒãŸprocess_imageãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼ˆç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦å‡¦ç†ã•ã‚Œã‚‹ï¼‰
            log_with_time(f"YOLO+DINOv2æ¤œå‡ºå®Ÿè¡Œ: ãƒ¢ãƒ¼ãƒ‰={current_detection_mode}, ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹={yolo_dinov2_pipeline.multiclass_mode}, æ¤œå‡ºé–¾å€¤={request.detectionThreshold}", level="INFO")
            processing_result = yolo_dinov2_pipeline.process_image(temp_image_path)
            
            # é–¾å€¤ã‚’å…ƒã«æˆ»ã™
            yolo_dinov2_pipeline.detection_conf_threshold = original_detection_threshold
            yolo_dinov2_pipeline.classification_conf_threshold = original_classification_threshold
            
            # çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            characters = []
            h, w = image_cv.shape[:2]
            
            for result in processing_result.results:
                x1, y1, x2, y2 = result.detection.bbox
                identification = result.identification
                
                # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—ï¼ˆæ­£è¦åŒ–ï¼‰
                center_x = (x1 + x2) / 2 / w
                center_y = (y1 + y2) / 2 / h
                
                # ä½ç½®ã‚’åˆ¤å®šï¼ˆå·¦ã€ä¸­å¤®ã€å³ï¼‰
                if center_x < 0.33:
                    position = "å·¦"
                elif center_x < 0.67:
                    position = "ä¸­å¤®"
                else:
                    position = "å³"
                
                # è¡¨æƒ…ã‚’æ¨å®šï¼ˆä¿¡é ¼åº¦ãƒ™ãƒ¼ã‚¹ï¼‰
                if identification.confidence > 0.8:
                    expression = "é€šå¸¸"
                elif identification.confidence > 0.6:
                    expression = "å¾®ç¬‘"
                else:
                    expression = "ä¸æ˜"
                
                # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®ã‚µã‚¤ã‚ºã‚’ç”»åƒæ¯”ç‡ã§è¨ˆç®—
                bbox_width = (x2 - x1) / w
                bbox_height = (y2 - y1) / h
                character_size_str = f"{bbox_width:.2f}, {bbox_height:.2f}"
                
                # è‹±èªåã‚’æ—¥æœ¬èªåã«ãƒãƒƒãƒ”ãƒ³ã‚°
                japanese_name = CHARACTER_NAME_MAP.get(identification.character_name, identification.character_name)
                
                # äººç‰©èªè­˜ï¼ˆåˆ†é¡ï¼‰ä¿¡é ¼åº¦ã‚’å°æ•°ç‚¹2æ¡ã§æ–‡å­—åˆ—åŒ–
                classification_confidence_str = f"{identification.confidence:.2f}"
                
                characters.append({
                    "character": japanese_name,
                    "faceDirection": "",  # ç©ºæ¬„
                    "position": classification_confidence_str,  # äººç‰©èªè­˜ä¿¡é ¼åº¦ã‚’è¡¨ç¤º
                    "shotType": "",  # ç©ºæ¬„
                    "characterSize": character_size_str,
                    "expression": "",  # ç©ºæ¬„
                    "clothing": "",  # ç©ºæ¬„
                    "isVisible": True,
                    "coordinate": [center_x, center_y],
                    "detectionConfidence": result.detection.confidence,
                    "classificationConfidence": identification.confidence,
                    "bbox": [float(x1), float(y1), float(x2), float(y2)]
                })
        
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if temp_image_path and os.path.exists(temp_image_path):
                os.unlink(temp_image_path)
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’å³ã‹ã‚‰å·¦ã®é †åºã§ã‚½ãƒ¼ãƒˆï¼ˆXåº§æ¨™ã®é™é †ï¼‰
        characters.sort(key=lambda c: -c.get("coordinate", [0, 0])[0])
        
        # æ¤œå‡ºã•ã‚Œãªã‹ã£ãŸå ´åˆã¯ç©ºã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’1ã¤è¿½åŠ 
        if not characters:
            characters.append({
                "character": "",
                "faceDirection": "",
                "position": "",
                "shotType": "",
                "characterSize": "0.00, 0.00",
                "expression": "",
                "clothing": "",
                "isVisible": True,
                "coordinate": [0, 0],
                "detectionConfidence": 0.0,
                "classificationConfidence": 0.0
            })
        
        # æ¤œå‡ºçµæœã‚’å¯è¦–åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        visualization = None
        visualization_error = None
        
        print(f"ğŸ” request.visualize = {request.visualize}")
        if request.visualize:
            import io
            import base64
            from PIL import Image
            
            # ç›´æ¥çš„ãªå¯è¦–åŒ–å‡¦ç†ï¼ˆæ—¢ã«èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
            try:
                print(f"å¯è¦–åŒ–é–‹å§‹: image_cv shape={image_cv.shape}")
                print(f"processing_result.resultsæ•°: {len(processing_result.results)}")
                
                # æ—¢å­˜ã®image_cvã‚’RGBå½¢å¼ã«å¤‰æ›
                import matplotlib.pyplot as plt
                import matplotlib.patches as patches
                from matplotlib import font_manager
                import cv2
                
                # RGBå½¢å¼ã«å¤‰æ›
                image_rgb = cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB)
                
                # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
                fig, ax = plt.subplots(1, 1, figsize=(12, 8))
                ax.imshow(image_rgb)
                
                # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’è©¦è¡Œ
                try:
                    font_path = '/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W3.ttc'
                    if os.path.exists(font_path):
                        prop = font_manager.FontProperties(fname=font_path)
                        plt.rcParams['font.family'] = prop.get_name()
                except:
                    pass
                
                # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¥è‰²è¨­å®š
                CHARACTER_COLORS = {
                    'yuzuko': (255, 105, 180),  # Hot Pink
                    'yukari': (30, 144, 255),   # Dodger Blue
                    'yui': (50, 205, 50),       # Lime Green
                    'yoriko': (255, 165, 0),    # Orange
                    'chiho': (138, 43, 226),    # Blue Violet
                    'kei': (220, 20, 60),       # Crimson
                    'fumi': (0, 206, 209),      # Dark Turquoise
                    'unknown': (128, 128, 128)  # Gray
                }
                
                # é‡è¤‡é™¤å»å‡¦ç†ï¼ˆIoU 0.3é–¾å€¤ï¼‰
                filtered_results = []
                for i, result in enumerate(processing_result.results):
                    is_duplicate = False
                    for j, other_result in enumerate(filtered_results):
                        # IoUè¨ˆç®—
                        x1_1, y1_1, x2_1, y2_1 = result.detection.bbox
                        x1_2, y1_2, x2_2, y2_2 = other_result.detection.bbox
                        
                        # äº¤å·®é ˜åŸŸ
                        intersection_x1 = max(x1_1, x1_2)
                        intersection_y1 = max(y1_1, y1_2)
                        intersection_x2 = min(x2_1, x2_2)
                        intersection_y2 = min(y2_1, y2_2)
                        
                        if intersection_x1 < intersection_x2 and intersection_y1 < intersection_y2:
                            intersection_area = (intersection_x2 - intersection_x1) * (intersection_y2 - intersection_y1)
                            area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
                            area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
                            union_area = area1 + area2 - intersection_area
                            iou = intersection_area / union_area if union_area > 0 else 0
                            
                            if iou > 0.3:  # é‡è¤‡ã¨åˆ¤å®š
                                is_duplicate = True
                                break
                    
                    if not is_duplicate:
                        filtered_results.append(result)
                
                print(f"é‡è¤‡é™¤å»: {len(processing_result.results)} -> {len(filtered_results)}äºº")
                
                # é‡è¤‡é™¤å»æ¸ˆã¿çµæœã‚’æç”»
                for i, face_result in enumerate(filtered_results):
                    x1, y1, x2, y2 = face_result.detection.bbox
                    character_en = face_result.identification.character_name
                    char_conf = face_result.identification.confidence
                    
                    # è‹±èªåã‚’æ—¥æœ¬èªåã«å¤‰æ›
                    character_jp = CHARACTER_NAME_MAP.get(character_en, character_en)
                    
                    # è‰²ã®é¸æŠ
                    color_rgb = CHARACTER_COLORS.get(character_en, CHARACTER_COLORS['unknown'])
                    color = tuple(c/255.0 for c in color_rgb)
                    
                    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ï¼ˆå¤ªç·šï¼‰
                    rect = patches.Rectangle(
                        (x1, y1), x2-x1, y2-y1,
                        linewidth=4, edgecolor=color, facecolor='none'
                    )
                    ax.add_patch(rect)
                    
                    # ãƒ©ãƒ™ãƒ«ã‚’å†…å´ã®é©åˆ‡ãªä½ç½®ã«é…ç½®
                    bbox_width = x2 - x1
                    bbox_height = y2 - y1
                    text_x = x1 + bbox_width * 0.02  # å·¦ç«¯ã‹ã‚‰å°‘ã—å†…å´
                    text_y = y1 + bbox_height * 0.95  # ä¸‹ç«¯è¿‘ã
                    
                    label = f'{character_jp} ({char_conf:.1%})'
                    
                    ax.text(
                        text_x, text_y, label,
                        color='white', fontsize=12, weight='bold',
                        bbox=dict(boxstyle='round,pad=0.3', facecolor=color, alpha=0.8, edgecolor='white', linewidth=1),
                        verticalalignment='bottom'
                    )
                
                ax.axis('off')
                mode_str = "ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹æ¤œå‡º" if yolo_dinov2_pipeline.multiclass_mode else "é¡”æ¤œå‡º+èªè­˜"
                character_names = [CHARACTER_NAME_MAP.get(r.identification.character_name, r.identification.character_name) for r in filtered_results]
                character_list = ", ".join(character_names) if character_names else "ãªã—"
                title = f'{mode_str} | æ¤œå‡º: {len(filtered_results)}äºº | ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: {character_list}'
                ax.set_title(title, fontsize=14, weight='bold')
                
                plt.tight_layout()
                
                # BufferIOã‚’ä½¿ç”¨ã—ã¦PNGå½¢å¼ã§ç”»åƒã‚’å–å¾—ï¼ˆMacäº’æ›ï¼‰
                buf = io.BytesIO()
                plt.savefig(buf, format='png', bbox_inches='tight', dpi=100)
                buf.seek(0)
                
                # PILã§èª­ã¿è¾¼ã‚“ã§Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                pil_image = Image.open(buf)
                final_buf = io.BytesIO()
                pil_image.save(final_buf, format='PNG')
                final_buf.seek(0)
                visualization_base64 = base64.b64encode(final_buf.read()).decode('utf-8')
                
                plt.close()
                buf.close()
                final_buf.close()
                
                # å¯è¦–åŒ–ç”»åƒã‚’çµæœã«è¿½åŠ 
                visualization = f"data:image/png;base64,{visualization_base64}"
                print("âœ… ç›´æ¥å¯è¦–åŒ–å‡¦ç†å®Œäº†ï¼ˆé‡è¤‡é™¤å»ãƒ»ãƒ©ãƒ™ãƒ«å†…å´é…ç½®é©ç”¨ï¼‰")
            except Exception as e:
                import traceback
                visualization_error = f"ã‚¨ãƒ©ãƒ¼: {str(e)} | ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯: {traceback.format_exc()[:500]}"
                print(f"âŒ å¯è¦–åŒ–å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                print(f"è©³ç´°ãªã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
                visualization = None
        
        # çµæœã‚’è¿”ã™
        mode_info = "ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹æ¤œå‡º" if yolo_dinov2_pipeline.multiclass_mode else "é¡”æ¤œå‡º+èªè­˜"
        model_description = "YOLO11l (8ã‚¯ãƒ©ã‚¹ç›´æ¥æ¤œå‡º)" if yolo_dinov2_pipeline.multiclass_mode else "YOLO11l + DINOv2"
        
        result = {
            "characters": characters,
            "charactersNum": len([c for c in characters if c["character"]]),
            "detectionStats": {
                "totalFaces": len(processing_result.results),
                "identifiedFaces": len([c for c in characters if c["character"]]),
                "processingTime": processing_result.processing_time
            },
            "model": model_description,
            "detectionMode": current_detection_mode,
            "modeDescription": mode_info,
            "modelInfo": {
                "detection": "YOLO11l (anime face)" if not yolo_dinov2_pipeline.multiclass_mode else "YOLO11l (multiclass)",
                "classification": "DINOv2 (8 classes)" if not yolo_dinov2_pipeline.multiclass_mode else "ç›´æ¥8ã‚¯ãƒ©ã‚¹æ¤œå‡º"
            },
            "debug": {
                "visualize_requested": request.visualize,
                "visualization_created": visualization is not None,
                "visualization_error": visualization_error if 'visualization_error' in locals() else None
            }
        }
        
        if visualization:
            result["visualization"] = visualization
        
        return JSONResponse(content=result)
        
    except Exception as e:
        log_with_time(f"YOLO+DINOv2æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}", level="ERROR")
        import traceback
        traceback.print_exc()
        return JSONResponse(
            content={"error": f"æ¤œå‡ºå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}"},
            status_code=500
        )


# ================== æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ==================

@app.post("/api/detection-mode")
async def set_detection_mode(request: DetectionModeRequest) -> DetectionModeResponse:
    """æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆ"""
    global current_detection_mode, yolo_dinov2_pipeline
    
    try:
        if request.mode not in ["face_recognition", "multiclass"]:
            return DetectionModeResponse(
                success=False,
                current_mode=current_detection_mode,
                message="ç„¡åŠ¹ãªãƒ¢ãƒ¼ãƒ‰ã§ã™ã€‚'face_recognition' ã¾ãŸã¯ 'multiclass' ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
            )
        
        if yolo_dinov2_pipeline is None:
            return DetectionModeResponse(
                success=False,
                current_mode=current_detection_mode,
                message="YOLO+DINOv2ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            )
        
        # ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹ãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆ
        multiclass_mode = (request.mode == "multiclass")
        yolo_dinov2_pipeline.set_mode(multiclass_mode)
        
        current_detection_mode = request.mode
        mode_name = "ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹æ¤œå‡º" if multiclass_mode else "é¡”æ¤œå‡º+èªè­˜"
        
        log_with_time(f"æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‚’{mode_name}ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸ", level="INFO")
        
        return DetectionModeResponse(
            success=True,
            current_mode=current_detection_mode,
            message=f"æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‚’{mode_name}ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸã€‚"
        )
        
    except Exception as e:
        log_with_time(f"æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆã‚¨ãƒ©ãƒ¼: {e}", level="ERROR")
        return DetectionModeResponse(
            success=False,
            current_mode=current_detection_mode,
            message=f"ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
        )


@app.get("/api/detection-mode")
async def get_detection_mode() -> DetectionModeResponse:
    """ç¾åœ¨ã®æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‚’å–å¾—"""
    mode_name = "ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹æ¤œå‡º" if current_detection_mode == "multiclass" else "é¡”æ¤œå‡º+èªè­˜"
    
    return DetectionModeResponse(
        success=True,
        current_mode=current_detection_mode,
        message=f"ç¾åœ¨ã®ãƒ¢ãƒ¼ãƒ‰: {mode_name}"
    )


@app.post("/api/detect-balloons")
async def detect_balloons(request: Dict[str, Any]):
    """å¹ãå‡ºã—æ¤œå‡ºå°‚ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        balloon_detector = get_balloon_detector()
        
        # ç”»åƒãƒ‘ã‚¹ã¾ãŸã¯Base64ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¤œå‡º
        if "imagePath" in request:
            image_path = "./public" + request["imagePath"]
            detections = balloon_detector.detect_from_path(
                image_path,
                confidence_threshold=request.get("confidenceThreshold", 0.25),
                max_det=request.get("maxDet", 300)
            )
        elif "imageBase64" in request:
            detections = balloon_detector.detect_from_base64(
                request["imageBase64"],
                confidence_threshold=request.get("confidenceThreshold", 0.25),
                max_det=request.get("maxDet", 300)
            )
        else:
            return JSONResponse(
                content={"error": "imagePath or imageBase64 is required"},
                status_code=400
            )
        
        return JSONResponse(content={
            "detections": detections,
            "count": len(detections)
        })
        
    except Exception as e:
        log_with_time(f"å¹ãå‡ºã—æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}", level="ERROR")
        return JSONResponse(
            content={"error": f"å¹ãå‡ºã—æ¤œå‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"},
            status_code=500
        )


@app.post("/api/crop-classify-balloons")
async def crop_classify_balloons(request: Dict[str, Any]):
    """å¹ãå‡ºã—æ¤œå‡ºãƒ»åˆ‡ã‚Šå‡ºã—ãƒ»åˆ†é¡ãƒ»å¯è¦–åŒ–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        balloon_detector = get_balloon_detector()
        
        # å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒã‚§ãƒƒã‚¯
        if "imagePath" not in request:
            return JSONResponse(
                content={"error": "imagePath is required"},
                status_code=400
            )
        
        image_path = "./public" + request["imagePath"]
        
        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        confidence_threshold = request.get("confidenceThreshold", 0.25)
        max_det = request.get("maxDet", 300)
        save_crops = request.get("saveCrops", True)
        output_dir = request.get("outputDir", "./tmp/balloon_crops")
        
        # å¹ãå‡ºã—æ¤œå‡ºãƒ»åˆ‡ã‚Šå‡ºã—ãƒ»åˆ†é¡ãƒ»å¯è¦–åŒ–ã‚’å®Ÿè¡Œ
        result = balloon_detector.crop_and_classify_balloons(
            image_path=image_path,
            confidence_threshold=confidence_threshold,
            max_det=max_det,
            save_crops=save_crops,
            output_dir=output_dir
        )
        
        # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆ
        if "error" in result:
            return JSONResponse(
                content={"error": result["error"]},
                status_code=500
            )
        
        # å¯è¦–åŒ–ç”»åƒãŒã‚ã‚‹å ´åˆã¯ã€å…¬é–‹å¯èƒ½ãªãƒ‘ã‚¹ã«å¤‰æ›
        if result.get("visualization_path"):
            # tmp/ã‹ã‚‰å§‹ã¾ã‚‹ãƒ‘ã‚¹ã‚’å…¬é–‹ãƒ‘ã‚¹ã«å¤‰æ›
            vis_path = result["visualization_path"]
            if vis_path.startswith("./tmp/"):
                # public/tmp/ã«ç§»å‹•ã—ã¦ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ã™ã‚‹
                public_tmp_dir = Path("./public/tmp")
                public_tmp_dir.mkdir(parents=True, exist_ok=True)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
                vis_filename = Path(vis_path).name
                public_vis_path = public_tmp_dir / vis_filename
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
                import shutil
                shutil.copy2(vis_path, public_vis_path)
                
                # å…¬é–‹ãƒ‘ã‚¹ã«æ›´æ–°
                result["visualization_path"] = f"/tmp/{vis_filename}"
        
        return JSONResponse(content={
            "success": True,
            "result": result
        })
        
    except Exception as e:
        log_with_time(f"å¹ãå‡ºã—åˆ‡ã‚Šå‡ºã—ãƒ»åˆ†é¡ã‚¨ãƒ©ãƒ¼: {e}", level="ERROR")
        return JSONResponse(
            content={"error": f"å¹ãå‡ºã—åˆ‡ã‚Šå‡ºã—ãƒ»åˆ†é¡ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"},
            status_code=500
        )


@app.post("/api/analyze-tail-shape")
async def analyze_tail_shape(request: Dict[str, Any]):
    """ã—ã£ã½ã®å½¢çŠ¶åˆ†æã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        from tail_shape_analyzer import TailShapeAnalyzer
        
        # å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒã‚§ãƒƒã‚¯
        if "imageBase64" not in request:
            return JSONResponse(
                content={"error": "imageBase64 is required"},
                status_code=400
            )
        
        if "tailBBox" not in request or "balloonBBox" not in request:
            return JSONResponse(
                content={"error": "tailBBox and balloonBBox are required"},
                status_code=400
            )
        
        # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–
        analyzer = TailShapeAnalyzer()
        
        # ã—ã£ã½ã®æ–¹å‘ã‚’åˆ†æ
        result = analyzer.analyze_tail_direction(
            image_base64=request["imageBase64"],
            tail_bbox=request["tailBBox"],
            balloon_bbox=request["balloonBBox"]
        )
        
        log_with_time(f"ã—ã£ã½å½¢çŠ¶åˆ†æå®Œäº†: å…ˆç«¯ç‚¹={result['tip_point']}", level="INFO")
        
        return JSONResponse(content=result)
        
    except Exception as e:
        log_with_time(f"ã—ã£ã½å½¢çŠ¶åˆ†æã‚¨ãƒ©ãƒ¼: {e}", level="ERROR")
        import traceback
        traceback.print_exc()
        return JSONResponse(
            content={"error": f"ã—ã£ã½å½¢çŠ¶åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"},
            status_code=500
        )

@app.post("/api/visualize-detection")
async def visualize_detection(request: Dict[str, Any]):
    """ç”»åƒã«æ¤œå‡ºçµæœã‚’å¯è¦–åŒ–ã—ã¦è¿”ã™"""
    try:
        from balloon_detection_integration import (
            BalloonDetector,
            draw_tail_shape_results_on_image,
            classify_tail_shapes_in_detections
        )
        import cv2
        import base64
        from io import BytesIO
        from PIL import Image
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        file_path = request.get("filePath")
        balloon_detection = request.get("balloonDetection", True)
        character_detection = request.get("characterDetection", False)
        tail_detection = request.get("tailDetection", True)
        
        if not file_path:
            return JSONResponse(
                content={"error": "filePath is required"},
                status_code=400
            )
        
        # ç”»åƒã‚’èª­ã¿è¾¼ã¿
        image = cv2.imread(file_path)
        if image is None:
            return JSONResponse(
                content={"error": f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}"},
                status_code=404
            )
        
        balloon_detections = []
        character_detections = []
        
        # å¹ãå‡ºã—æ¤œå‡º
        if balloon_detection:
            detector = BalloonDetector()
            balloon_detections = detector.detect_balloons(
                image,
                confidence_threshold=0.25,
                max_det=300,
                detect_tails=tail_detection
            )
            
            # ã—ã£ã½å½¢çŠ¶åˆ†é¡
            if tail_detection:
                balloon_detections = classify_tail_shapes_in_detections(image, balloon_detections)
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ¤œå‡º
        if character_detection:
            # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ¤œå‡ºã‚’å®Ÿè¡Œï¼ˆYOLOã¾ãŸã¯DinoV2ã‚’ä½¿ç”¨ï¼‰
            try:
                from yuyu_yolo_dinov2_pipeline import detect_characters_yolo_dinov2
                yolo_model_path = "/Users/esuji/work/fun_annotator/yolo11x_face_detection_model/yolo11l_480_12_14.pt"
                dinov2_model_path = "/Users/esuji/work/fun_annotator/yuyu_face_recognize_model/yuyu_dinov2_final.pth"
                
                char_results = detect_characters_yolo_dinov2(
                    image,
                    yolo_model_path=yolo_model_path,
                    dinov2_model_path=dinov2_model_path,
                    confidence_threshold=0.25
                )
                character_detections = char_results["characters"]
            except Exception as e:
                log_with_time(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}", level="WARNING")
        
        # çµæœã‚’ç”»åƒã«æç”»
        result_image = draw_tail_shape_results_on_image(
            image,
            balloon_detections,
            character_detections
        )
        
        # ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        result_bgr = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)
        _, buffer = cv2.imencode('.png', result_bgr)
        image_base64 = base64.b64encode(buffer).decode('utf-8')
        
        return JSONResponse(content={
            "success": True,
            "imageBase64": f"data:image/png;base64,{image_base64}",
            "detections": {
                "balloons": balloon_detections,
                "characters": character_detections
            }
        })
        
    except Exception as e:
        log_with_time(f"å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}", level="ERROR")
        import traceback
        traceback.print_exc()
        return JSONResponse(
            content={"error": f"å¯è¦–åŒ–å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"},
            status_code=500
        )

@app.get("/api/debug-visualization")
async def debug_visualization():
    """å¯è¦–åŒ–å‡¦ç†ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å–å¾—"""
    try:
        pipeline_available = yolo_dinov2_pipeline is not None
        visualize_method_available = hasattr(yolo_dinov2_pipeline, "visualize_results") if pipeline_available else False
        
        test_result = "æœªå®Ÿè¡Œ"
        if pipeline_available and visualize_method_available:
            try:
                # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚¹ãƒˆç”»åƒã§å¯è¦–åŒ–ãƒ†ã‚¹ãƒˆ
                test_image = "public/test_detection_image.jpg"
                if os.path.exists(test_image):
                    result = yolo_dinov2_pipeline.process_image(test_image)
                    visualized = yolo_dinov2_pipeline.visualize_results(
                        image_path=test_image,
                        result=result,
                        show=False,
                        use_character_colors=True
                    )
                    test_result = f"æˆåŠŸ: {visualized.shape}"
                else:
                    test_result = "ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚‰ãªã„"
            except Exception as e:
                import traceback
                test_result = f"ã‚¨ãƒ©ãƒ¼: {str(e)} | {traceback.format_exc()[:200]}"
        
        return {
            "message": "ãƒ‡ãƒãƒƒã‚°æƒ…å ±å–å¾—æˆåŠŸ",
            "pipeline_available": pipeline_available,
            "visualize_method_available": visualize_method_available,
            "test_result": test_result
        }
    except Exception as e:
        import traceback
        return {
            "message": f"ãƒ‡ãƒãƒƒã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}",
            "pipeline_available": False,
            "visualize_method_available": False,
            "test_result": f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {traceback.format_exc()[:200]}"
        }

